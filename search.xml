<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[利用支持集中匹配信息的 few shot 事件分类方法]]></title>
      <url>%2F2020%2F04%2F16%2F%E5%88%A9%E7%94%A8%E6%94%AF%E6%8C%81%E9%9B%86%E4%B8%AD%E5%8C%B9%E9%85%8D%E4%BF%A1%E6%81%AF%E7%9A%84-few-shot-%E4%BA%8B%E4%BB%B6%E5%88%86%E7%B1%BB%E6%96%B9%E6%B3%95%2F</url>
      <content type="text"><![CDATA[论文基本信息 论文标题：Exploiting the Matching Information in the Support Set for Few Shot Event Classification论文作者：Viet Dac Lai, Franck Dernoncourt, and Thien Huu Nguyen1论文出处：PAKDD2020论文原文地址：https://arxiv.xilesou.top/pdf/2002.05295.pdf 论文正文 摘要：现有的事件分类（EC）工作主要集中在传统的有监督的学习环境中，在这种环境中，模型无法提取新的/不可见的事件类型。在这一领域还没有对few-shot学习进行研究，尽管它使EC模型能够将其操作扩展到未观察到的事件类型。为了填补这一空白，在这项工作中，我们研究了在few-shot学习背景下的事件分类。针对这一问题，我们提出了一种新的训练方法，该方法广泛利用了训练过程中的支持集。特别是，除了将查询示例与用于训练的支持集中的示例进行匹配外，我们还寻求进一步匹配支持集本身中的示例。该方法为模型提供了更多的训练信号，可以应用于各种基于度量学习的few-shot学习方法。我们在两个基准的EC数据集上进行了大量的实验，结果表明所提出的方法可以将所报告的最佳few-shot学习模型的事件分类准确率提高10%。关键词：事件分类，辅助损失，few-shot学习 Introduction&emsp;&emsp;事件分类(EC)是自然语言处理(NLP)中信息抽取(IE)的一项重要工作。EC的目标是对一些事件类型集（即类）的事件提及(Event mentions)进行分类。事件提及(Event mentions)通常与一些词汇/短语相关，这些词汇/短语负责触发句子中相应的事件。例如，考虑以下两句话:(1) The companies fire the employee who wrote anti-diversity memo.(2) The troops were ordered to cease fire.在这些示例中，EC系统应该能够将上述两句话中的“fire”分别归类为雇佣终止事件和攻击事件。通过例子可以看出，EC中一个值得注意的挑战是，单词的相似表面形式可能会根据上下文表达不同的事件。EC采用了两种主要方法。第一种方法探索语言特征(例如，语法和语义属性)来训练统计模型[9]。另一方面，第二种方法侧重于开发深度神经网络模型（例如卷积神经网络（CNN）和递归神经网络（RNN）），以从大规模数据集中自动学习有效特征[5,13]。由于深度学习模型的发展，EC的性能得到了显著的提高[19,17,16,14,23]。&emsp;&emsp;目前的EC模型主要采用传统的监督学习设置[19,17]，其中用于分类的事件类型集合已经被预先确定。然而，一旦使用给定的事件类型集在数据集上对模型进行训练，它就无法检测到不可见事件类型的事件提及(Event mentions)。要将EC扩展到新的事件类型，一种常见的解决方案是为此类新事件类型注释额外的培训数据并重新培训模型，这是非常昂贵的。因此，我们希望在few-shot学习的环境中形式化EC，在这种环境中，系统需要学习从少数例子中识别新事件类型的事件提及(Event mentions)。事实上，这更接近于人类如何学习执行任务，并使EC模型更适用于实践。然而，据我们所知，目前还没有关于few-shot学习的研究。&emsp;&emsp;在few-shot学习中，我们得到了一个支持集和一个查询实例。支持集包含一组类的示例(例如EC中的事件)。学习模型需要在支持集中显示的类中预测查询实例所属的类。这是基于查询示例和支持集中的示例之间的匹配信息完成的。要应用此设置来提取某个新类型的示例，我们只需要收集几个新类型的示例，然后将它们添加到支持集中以形成一个新类。之后，每当我们需要预测一个新示例是否具有新类型时，我们可以将其设置为查询示例并在此设置中执行模型。&emsp;&emsp;实际上，我们经常有一些现有的数据集（用D表示），并带有一些预定义类型的示例。因此，先前关于few-shot学习的工作已经利用这些数据集来模拟前面提到的few-shot学习设置来训练模型[26]。基本上，在培训过程的每个阶段，都会对D中的类型子集进行采样，并为每个类型选择一些示例作为支持集。还从每种抽样类型的其余示例中选择了一些其他示例来建立查询点。然后，将根据示例的上下文匹配对模型进行训练，以将查询示例正确映射到支持集中的相应类型[7]。&emsp;&emsp;此训练过程的一个潜在问题是，模型的训练信号仅来自查询示例和支持集中的示例之间的匹配信息。现有的few-shot学习工作[28,26]，特别是对于NLP任务[7]，还没有探索支持集本身中示例之间的可用匹配信息。虽然这种方法对于计算机视觉中的任务是可以接受的，但是对于NLP应用程序，特别是对于EC，可能就不太合适了。总体而言，NLP中的数据集比计算机视觉中的数据集要小得多，因此限制了用于训练目的的上下文的多样性。对支持集中的示例的匹配信息的不了解可能会导致在EC训练数据的使用中效率低下，因为模型无法充分利用可用信息并且无法获得良好的性能。因此，在这项工作中，我们建议同时利用支持集中的示例之间以及查询示例与支持集中的示例之间的匹配信息，以训练EC的少量学习模型。这是通过在损失函数中添加附加项（即辅助损失）来实现的，以捕获支持集中的示例之间的匹配知识。我们期望这种新的训练技术能更好地利用训练数据，提高EC中few-shot学习的性能。&emsp;&emsp;我们将提出的训练方法广泛应用于不同的度量学习模型，以便在两个基准EC数据集上进行few-shot学习。实验表明，新的训练技术可以在性能差距较大的两个数据集上显著改善所有考虑的few-shot学习方法。总而言之，这项工作的贡献包括: (1)我们在文献中首次研究了事件分类的few-shot学习问题，（2）提出了一种新的基于度量学习的few-shot学习模型训练方法。所提出的训练方法利用支持集中的例子之间的匹配信息作为附加训练信号，（3）我们在few-shot学习环境中获得了EC的最新性能，并作为该领域未来研究的基准。 Related Work&emsp;&emsp;早期的事件分类研究主要集中在为统计模型设计语言特征[1,9,12]。由于深度学习的发展，许多先进的网络结构被用来提高事件分类的准确性[5,19,17,18,21,13,22]。然而，没有一个像我们在这项工作中所做的那样，为EC研究few-shot学习问题。虽然最近的一些研究已经考虑了一个相关的设置，其中事件类型用一些关键字进行了扩充[3,24,11]，但这些工作并没有像我们在这项工作中所做的那样明确地检查few-shot学习设置。本文还对事件分类中的zero-shot学习进行了一些研究[8]。&emsp;&emsp;Few-shot学习有助于模型在没有大规模数据的情况下学习有效的潜在特征。早期的研究将迁移学习应用于对预先训练好的模型进行微调，利用足够的实例从公共类中挖掘潜在的信息[4,2]。另一方面，度量学习则是学习对观察到的类之间的距离分布进行建模[10,28,26]。最近，元学习中引入了快速学习的概念，这种学习可以很快地概括为一个新的概念[25,6]。在这些方法中，与迁移学习和元学习相比，度量学习更易于解释，更易于训练和实施。值得注意的是，度量学习中的典型网络在几个FSL基准上取得了最新的性能，并显示了其对噪声数据的鲁棒性[26,7]。虽然有许多FSL方法被提出用于图像识别[10,28,26,6,25]，但是针对NLP问题的这种设置的研究很少[7,29]。 MethodologyNotation&emsp;&emsp;Few-shot事件分类的任务是在给定一个支持集S和一组事件类型T={t1，t2，tN}（N是事件类型的数目）,来预测查询示例x的事件类型。在few-shot学习中，S包含了T中每个事件类型的几个示例。为了方便起见，我们将支撑集表示为：其中(s_i^j,a_i^j,t_i)表示s_i^j语句中的a_i^j-th单词是事件类型t_i提到的触发单词，K_1,K_2,…,K_N分别代表的是对于t_1,t_2,…,t_N中的每一种类型在支持集中的示例数量。为了简单起见，我们使用w_1,w_2,…,w_l表示在这项工作中某个长度为l的句子的单词序列。&emsp;&emsp;类似地，查询示例x也可以用x=（q，p，t）表示，其中q，p和t分别表示查询语句、语句中触发词的位置和该事件提及的真正事件类型。注意t∈T只在训练时间内提供，模型需要在测试时间内预测该事件类型。&emsp;&emsp;实际上，S中的支持示例的数量（即K_1,K_2,…,K_N）可能有所不同。但是，为了简化处理并使用GPU加快训练过程，类似于FSL中的最新研究[7]，我们采用了N-way K-shot FSL设置。在此设置中，支持集中每个类的实例数相等（K_1=⋯ K_N=K&gt;1）和小（K∈{5,10}）。&emsp;&emsp;请注意，为了评估EC的few-shot学习模型，我们需要训练数据Dtrain和测试数据Dtest。对于few-shot学习，关键是Dtrain和Dtest中的事件类型集合是不相交的。每一集的事件类型集合T将是Dtrain或Dtest中事件类型集合的一个样本，分别取决于训练和评估时间。另外，如引言中所述，在训练过程的一个阶段中，将对一组查询示例（即查询集）进行采样，以使其涉及与支持集相似的事件类型T，以及每种类型的示例查询集中的内容将与支持集中的内容不同。在测试时，将对测试集中所有样本的模型分类精度进行评估。 Few-shot Learning for Event Classification本工作中EC的few-shot学习框架遵循典型网络中的典型度量学习结构[26,7]，涉及到三个主要组件:实例编码器(instance encoder)、原型模块(prototypical module)、分类器模块(classifier module)。 Instance encoder 给定一个句子s={w_1,w_2,…,w_l}和触发词a的位置（即w_a是在句子s中事件提及的触发词，(s,a)是S或查询示例中的示例），遵循EC[19,5]中的一般做法，我们首先将每个单词w_i∈s转换成实值向量，以便于在接下来的步骤中进行神经计算。特别是，在这项工作中，我们使用以下两个向量的连接来表示每个单词w_i： w_i的预训练词嵌入:这个向量被期望用来捕获w_i隐藏的语法和语义信息[15]。 w_i的位置嵌入：该向量是通过将其与触发词w_a（即i - a）的相对距离映射到位置嵌入表中的嵌入向量而获得的。位置嵌入表在模型训练过程中随机初始化和更新。位置嵌入向量的目的是明确地告知模型触发词在句子中的位置[5]。 &emsp;&emsp;在将w_i转换成表示向量ei之后，输入语句s成为表示向量E = e1，e2，…el的序列。基于这个向量序列，一个神经网络结构f将会被用来将E转换成一个整体的表示向量v来对输入的例子(s, m)进行编码(v = f(s, m))。在这项工作中，我们研究了编码函数f的两种网络架构，即一个是基于CNN的早期EC架构，另一个是基于Transformer的最近流行的NLP架构:&emsp;&emsp;CNN encoder: 该模型对输入向量序列E进行窗口大小为k和多个滤波器的时域卷积运算，对输入语句的每个位置生成一个隐藏向量。然后通过最大池操作对这些隐藏向量进行聚合，得到(s, m)的整体表示向量v[5,7]。&emsp;&emsp;Transformer encoder：这是一种先进的基于注意机制的矢量序列编码模型，不需要递归神经网络[27]。Transformer 编码器(encoder)涉及多层; 它们中的每一个都使用来自前一层的隐藏向量序列来生成当前层的隐藏向量序列。第一层以E为输入，而最后一层返回的隐藏向量序列(即触发字位置a处的向量)构成整个表示向量v。transformer编码器中的每一层都由两个子层（即多头的自我关注层和前馈层）组成，并在其周围增加一个剩余连接[27]。 Prototypical module 原型模块旨在计算单个原型向量来表示支持集T中的每个类。在这项工作中，我们考虑了文献中这个原型模块的两个版本。第一个版本来自原始的原型网络[26]。它仅使用支持集S中事件类型为ti的示例的表示向量的平均值来获取类ti的原型向量ci：&emsp;&emsp;另一方面，第二个版本来自基于混合注意力的原型网络[7]。原型向量是支持集中实例的表示向量的加权和。示例权重(即注意力权重)是由支持集中的示例与查询示例x = (q, p, t)的相似度决定的:&emsp;&emsp;在这个公式中，⊙是逐元素的乘法，sum是在输入向量的所有维度上进行的求和运算。 Classifier module 在本模块中，我们使用查询示例x = (q, p, T)到支持集中类/事件类型T的原型的距离，计算x在T中可能的类型的概率分布:其中d为距离函数，ci和cj分别为式(2)和式(3)中的原型向量。&emsp;&emsp;在本文中，我们考虑了三种常用的距离函数在不同的few-shot学习模型中使用度量学习: 匹配网络中的余弦相似度(称为Matching)[28]。 原型网络中的欧氏距离。根据原型向量是用方程2还是用方程3来计算，我们有两种不同的距离函数，分别称为Proto[26]和Proto+Att（即基于混合注意的原型网络[7]）。 在关系网络中使用卷积神经网络的可学习距离函数（称为Relation）。给定概率分布P（y | x，S），训练few-shot学习框架的典型方法是优化x的负对数似然函数（t为x的基本真值事件类型）[26,7]： Matching the examples in the support set 等式5中的典型few-shot学习损失函数旨在通过原型向量将查询示例x与支持集S中的示例匹配来学习的。这种机制的一个问题是它只使用查询示例和支持示例之间的匹配信号进行训练。这对于大型数据集（例如，在计算机视觉中）是可以接受的，其中许多示例可以扮演查询示例的角色，为学习过程提供足够的训练信号。然而，对于EC，可用的数据集通常很小（例如，ACE 2005数据集只有大约几千个带注释的事件提及），这使得仅依赖查询示例来训练信号的效率降低。换言之，对于EC查询匹配的有限数据，few-shot学习框架可能无法得到很好的训练。因此，在这项工作中，我们提出通过额外利用支持集中的实例之间的匹配信息，为EC引入更多的训练信号以进行few-shot学习。特别是，由于支持集中每个类/类型有多个示例（尽管只有几个），因此我们为S中的每种类型选择了此类示例的子集，并增强模型使其能够将所选示例与其剩余支持集中的相应类型进行匹配。&emsp;&emsp;在给定辅助支持集s^s的情况下，通过将辅助查询集S^Q中的示例与s^s进行匹配，寻求增强few-shot模型的训练信号。具体来说，我们首先在实例编码器和原型模块中使用相同的网络来计算辅助支持集s^s的T类的辅助原型。对于每个辅助实例z=（s_z,a_z,t_z）∈S^Q（s_z,a_z 和t_z分别是z中的句子、触发词位置和事件类型），我们使用分类器模块中的网络，基于辅助支持集s^s获得z中可能事件类型的概率分布P（.| z，s^s）。之后，我们通过引入辅助损失函数，增强模型可以正确预测辅助查询集S_ⅈ^Q中所有示例的事件类型（给定支持集s^s）：最后，本文中训练模型所需优化的总损失函数为：其中λ是主损失函数和辅助损失函数之间的权衡参数。为了方便起见，在以下实验中，我们将用于few-shot学习中具有辅助损失功能的训练方法称为LoLoss（即遗忘损失）。 ExperimentsDatasets&emsp;&emsp;我们在ACE 2005上评估了本研究中的所有模型。ACE 2005包含33个事件子类型，分为8种事件类型：业务(Business)、联系(Contact)、冲突(Conflict)、正义(Justice)、生活(Life)、移动(Movement)、人员(Personnel)和事务(Transaction)。另一方面，TAC KBP数据集包含9种事件类型的38个事件子类型。由于事件子类型的数量较多，我们将使用这些数据集中的子类型作为few-shot学习问题的类。&emsp;&emsp;由于我们希望在训练数据中最大化示例的数量，对于每个数据集（即，ACE 2005或TAC KBP 2015），我们在4个事件类型中选择示例总数最少的事件子类型，并以1:1的比率拆分为测试和开发类。按照这种启发式方法来选择类，ACE 2005中用于训练数据的事件类型涉及业务(Business)、联系(Contact)、冲突(Conflict)和正义(Justice)，而用于测试和开发数据的事件类型是生活(Life)、移动(Movement)、人员(Personnel)和事务(Transaction)。对于TAC KBP 2015，培训课程包括业务(Business)、联系(Contact)、冲突(Conflict)、正义(Justice)和制造(Manufacture)，而测试和开发课程包括生活(Life)、移动(Movement)、人员(Personnel)和事务(Transaction)。最后，由于打算遵循先前的几次学习的工作，在支持集中每个类有10个示例，在查询集中每个类有5个示例进行训练[7],因此我们删除了在数据集的训练，测试和开发集中少于15个示例的任何子类型的示例。 Hyper-Parameters&emsp;&emsp;类似于先前的工作[7]，我们使用N，K∈{5,10}的N-way K-shot FSL设置评估所有模型。对于训练，我们避免在每个批次中输入相同的事件子类型集，以使训练批次更加多样化。因此，根据文献[7]，我们为每个培训批次采样了20个事件子类型，同时在测试时间内仍保留5个或10个类。&emsp;&emsp;我们使用预先训练的300维GloVe嵌入初始化单词嵌入。单词嵌入在训练期间如文献[20]中所述进行更新。我们还随机初始化了50维的位置嵌入向量。根据数据集的开发数据选择其他参数，从而导致ACE 2005和TAC KBP 2015的参数相似。尤其是，CNN编码器包含一个窗口大小为3和250个过滤器的CNN层。我们设法使用这个简单的CNN编码器与之前的研究进行公平的比较[7]。Transformer编码器在注意机制中包含2个层，上下文大小为512，并且包含10个头部。辅助查询集Q中每个类别的示例数设置为2，而损失函数中的权衡参数λ为0.1。我们使用学习率为0.001的随机梯度下降来优化模型。 Results&emsp;&emsp;表1显示了使用CNN编码器和Transformer编码器的ACE 2005测试数据集上模型的准确性（即Matching、Proto、Proto+Att和Relation）。从表中可以看出几点。首先，比较实例编码器，很明显，在所有可能的few-shot学习模型和EC设置中，transformer编码器明显优于CNN编码器。第二，与few-shot学习模型相比，原型网络在所有设置下都显著优于Matching 和Relation，且性能差距较大。在原型网络中，Proto+Att的性能优于Proto，验证了原型模块基于注意机制的优点。第三，比较两组（5-way 5-shot VS 5-way 10-shot）和（10-way 5-shot VS 10-way 10-shot），我们发现在不同的设置下，当K值较大（即支持集中每个类的示例数）时，模型的性能几乎总是更好的，与自然直觉一致，即有更多的训练实例的好处。&emsp;&emsp;最重要的是，我们发现使用LoLoss程序训练模型将显著提高模型的性能。这适用于不同的few-shot学习模型、N-way k -shot设置和编码器选择。实验结果清楚地证明了所提出的训练程序利用支持集中的示例之间的匹配信息进行EC的few-shot学习的有效性。为简单起见，在下面的分析中，我们仅关注最佳的few-shot学习模型（即原型网络）和5-way 5-shot 与10-way 10-shot下的Transformer编码器。尽管我们在表2和表3中以较少的设置和模型显示了结果，但对于其他模型和设置也观察到了相同的趋势。&emsp;&emsp;表2还报告了TAC KBP 2015数据集上基于transformer的模型的准确性。从表中可以看出，我们对ACE 2005数据集的大部分观察结果仍然适用于TAC KBP 2015，再次证实了本文提出的LoLoss技术的优势。 Robustness against noise在这一部分中，我们试图评估few-shot学习模型对训练数据中可能存在的噪声的鲁棒性。特别地，在每一个训练集中，对T中的每种类型采样一组示例以形成查询集Q，我们通过随机选择Q中的一部分示例进行标签扰动来模拟噪声数据。本质上，对于Q的选定子集中的每个示例，我们将其原始标签更改为T中的另一个随机标签，使其成为带有错误标签的噪声示例。通过更改Q中用于标签扰动的选定部分的大小，我们可以控制EC中FSL训练过程中的噪声水平。表3显示了Proto + Att模型在ACE 2005测试集上的准确性，该模型采用带有或不带有LoLoss训练程序的Transformer编码器以用于不同的噪声率。从表中可以看出，引入噪声数据通常会降低模型的准确性（即，将表3中的单元与表1中基于Proto + Att的模型进行比较）。然而，在不同的噪声率和N-way K-shot设置下，使用LoLoss训练的Proto+Att模型始终明显优于未使用LoLoss的模型。在不同的设置下，性能差距至少是4.5%。事实上，我们发现LoLoss对Proto+Att的改善在有噪声的情况下(即至少4.5%)比无噪声的情况下更加显著(即。在表1中，5-way 5-shot 和10-way 10-shot的设置最多为3.3%)。这些证据进一步证实了LoLoss利用支持集中样本间的匹配信息来进行fen-shot学习的有效性和对噪声数据的鲁棒性。 Conclusion在这篇论文中，我们进行了第一个研究few-shot学习的事件分类。我们针对此问题研究了不同的量度学习方法，以典型的原型网络框架为特色，并为实例编码器（即CNN和Transformer）提供了多种选择。此外，我们提出了一种新的技术，称为LoLoss，用于训练基于支持集实例匹配信息的EC的few-shot学习模型。提出的LoLoss技术适用于不同数据集和设置的不同few-shot学习方法，有助于显著提高基线模型的性能。在未来，我们计划对LoLoss进行few-shot学习，以解决其他NLP和视觉问题(如关系提取、图像分类)。 AcknowledgmentsThis research has been supported in part by Vingroup Innovation Foundation (VINIF) in project code VINIF.2019.DA18 and Adobe Research Gift. This research is also based upon work supported in part by the Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Pro References略！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[精确率和召回率]]></title>
      <url>%2F2020%2F04%2F12%2F%E7%B2%BE%E7%A1%AE%E7%8E%87%E5%92%8C%E5%8F%AC%E5%9B%9E%E7%8E%87%2F</url>
      <content type="text"><![CDATA[简介 接下来，将对精确率和召回率，这两个概念进行解析。 定义辨析&emsp;&emsp;实际上非常简单，精确率是针对我们预测结果而言的，它表示的是预测为正的样本中有多少是真正的正样本。那么预测为正就有两种可能了，一种就是把正类预测为正类(TP)，另一种就是把负类预测为正类(FP)，也就是&emsp;&emsp;而召回率是针对我们原来的样本而言的，它表示的是样本中的正例有多少被预测正确了。那也有两种可能，一种是把原来的正类预测成正类(TP)，另一种就是把原来的正类预测为负类(FN)。其实就是分母不同，一个分母是预测为正的样本数，另一个是原来样本中所有的正样本数。在信息检索领域，精确率和召回率又被称为查准率和查全率，查准率＝检索出的相关信息量 / 检索出的信息总量查全率＝检索出的相关信息量 / 系统中的相关信息总量 小例子&emsp;&emsp;假设我们手上有60个正样本，40个负样本，我们要找出所有的正样本，系统查找出50个，其中只有40个是真正的正样本，计算上述各指标。 TP: 将正类预测为正类数 40 FN: 将正类预测为负类数 20 FP: 将负类预测为正类数 10 TN: 将负类预测为负类数 30 准确率(accuracy) = 预测对的/所有 = (TP+TN)/(TP+FN+FP+TN) = 70% 精确率(precision) = TP/(TP+FP) = 80% 召回率(recall) = TP/(TP+FN) = 2/3]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[衡量Facebook对研究反应的多样性]]></title>
      <url>%2F2020%2F04%2F07%2F%E8%A1%A1%E9%87%8FFacebook%E5%AF%B9%E7%A0%94%E7%A9%B6%E5%8F%8D%E5%BA%94%E7%9A%84%E5%A4%9A%E6%A0%B7%E6%80%A7%2F</url>
      <content type="text"><![CDATA[论文基本信息 论文标题：Measuring the Diversity of Facebook Reactions to Research论文作者：C. Freeman and H. Alhoori and M. Shahzad论文出处：Proceedings of the ACM on Human-Computer Interaction (2020)论文原文地址：https://arxiv.org/abs/2001.01029 论文正文 摘要：在网上和现实世界中，社区通过围绕核心问题达成的情感共识联系在一起。对科学发现的情感反应往往在这些核心问题中起着关键作用。当人们对科学话题的看法过于多样化时，情绪就会爆发并引发冲突。这场冲突威胁着研究的积极成果。情感有能力塑造人们处理新信息的方式。它们可以影响公众对科学的理解，激励政策立场，甚至改变生活。然而，很少有人用定量的方法来评估公众对科学的情绪反应。在这篇文章中，我们使用一组对Facebook上学术文章的回应数据集来分析情绪的效价、强度和多样性的动态。我们提出了一种新的方法来加权基于点击的反应，增加了它们的可理解性，并使用这些加权反应来开发新的情绪反应聚合指标。我们使用我们的指标以及LDA主题模型和统计测试来调查用户的情绪反应在不同科学主题之间的差异。我们发现，与性别、遗传学或农业/环境科学相关的研究文章引起的用户情绪反应与其他研究主题明显不同。我们还发现，人们对Facebook上的科学研究普遍有积极的反应，而产生积极情绪反应的文章更有可能被广泛分享——这一结论与之前对其他社交媒体平台的研究相矛盾。附加关键词和短语：社交计算，Facebook反应，社交媒体，网络挖掘，文本分析，情绪，情绪检测，基于点击的反应，高度度量 Introduction&emsp;&emsp;社交媒体平台上的信息共享和反应速度正逐年提高。2019年6月，Facebook每分钟新增29.3万条帖子和51万条评论[1]。这些平台通过基于点击的反应等功能进一步加快了内容评估和反馈的速度。这些相对较新的功能为用户提供了一种快速简便的方式，以一种仍然是个人和表达的方式对内容做出反应。它们已经在Facebook和LinkedIn等平台上推出，Facebook在2016年扩大了反应范围，LinkedIn在2019年增加了用户可点击的反应数量。然而，到目前为止，很少有研究来增进我们对这些新颖特征的理解。&emsp;&emsp;基于点击的反应为文献计量学和替代计量学（或替代度量）领域的研究人员提供了明显的好处，这样的领域是一个考虑到通过多个社交媒体平台传播研究结果的日益增长的兴趣领域[2–5]。以前的研究把引文作为理解和预测学术研究对科学界本身的影响的金标准[6]，但是评估工作可能对社会产生的情感影响在很大程度上没有受到影响。基于点击的反应可以提供一种方法来解决研究如何影响社会的问题。&emsp;&emsp;通常情况下，科学认识的进步之前是测量的进步。虽然已有成熟的方法和工具来分析文本的情感，但基于点击的反应的新颖性意味着，没有相同的资源来分析通过点击表达的情感。在本文中，我们提出了一个启发式的方法来分析基于点击的对社交媒体内容的响应。我们从心理学研究中借用了情绪效价、强度和多样性的概念，利用它们来更好地了解Facebook用户是如何通过他们的反应对科学研究做出回应的。在仔细分析了我们为这项研究收集的Facebook反应数据之后，我们为这些情感概念制定了衡量标准。最后，我们将新开发的方法和度量标准应用于我们的数据。我们最感兴趣的是学习关于科学主题的聚合行为和情感，而不是单个文章，因此，我们使用LDA主题模型在数据集中对文章进行聚类，并进行统计测试以了解用户如何基于共享内容表达情感变化。 Background我们首先定义几个重要术语： Click-based reactions：社交媒体平台上的功能，允许用户对内容做出快速、轻松的响应；基于点击的反应是非文本的，与文本表情符号相关，表情符号通过象形图传达情感反应；在Facebook上，基于点击的反应包括六个按钮“Like”，“Love”、“Wow”、“laughter”、“Sad”和“Anger”；图1显示了Facebook的六个基于点击的反应。 Five special reactions：基于五个点击的反应：“Love”、“Wow”、“laugh”、“Sad”和“Anger”。 Page visibility：Facebook页面拥有的关注者数量；Facebook允许用户喜欢或关注页面；在跟踪一个页面之后，用户将开始在自己的时间轴上看到由这些页面共享的内容。 Shares：一篇文章发布到Facebook上的公共页面的数量。 Reshares：用户在另一个私人或公共页面上重新共享文章的公共帖子的次数。我们的数据集包含对初始共享的反应和“重新共享”的数量，但是我们没有来自文章“重新共享”的反应数据。 Article：我们的数据集包含了Facebook对研究相关文章的反应；为了方便起见，这些文档有时被称为“documents”，特别是在特征转换的描述中。 Measuring emotion&emsp;&emsp;在评估一组用户对社交媒体内容的情绪反应时，有三个因素特别相关：反应的效价、强度和多样性。在心理学文献中，这些因素通常指个体的情绪反应[7-11]。由于我们有兴趣在这里测量聚合响应，因此我们将这三个变量视为对内容的聚合响应的指示。由于许多原因，我们收集的数据不可能对单个用户进行测量。首先，我们采取了预防措施，避免收集可用于识别特定用户的信息；测量更细致的情绪反应必然需要更多关于个体的信息。其次，每个用户只能在一篇文章上点击一个反应（但是，他们可以分享和提供对一篇文章的反应）。尽管这一信息有助于发现群体反应，但对于确定一个人对某篇论文的反应是多样的或者是有冲突的，一点帮助也没有。&emsp;&emsp;反应效价表示情绪的“方向”（即积极或消极）。积极的情绪会促进社交联系和娱乐性[8]，而消极的情绪会促进警惕和回避，尽管它们有时比积极的情绪更能吸引注意力[7，12]。效价是一种二元测量方法，重要的是要注意到消极反应对个人和社区都有有益的影响[12]。情绪反应的强度反映了信息对被调查者的重要性[9，13，14]。随着情绪强度的增加，情绪对象吸引了更多的个体注意力[7，10，15，16]。强度也可以用作信息在人的记忆中保留多长时间的指标[12]。更强烈的情绪也更有可能影响决策[17]。&emsp;&emsp;我们在这里使用的最后一个因素是反应的多样性。它表示用户对帖子的反应同时指向不同情感方向的程度。它可能表明内容有争议，或者对于一组应答者应该如何接收或解释一个主题没有共识。对一篇文章或文章的情绪反应的多样性表明，个体的反应有很大的差异，而且对某个特定的主题或问题没有达成共识[11]。 Topic models&emsp;&emsp;主题模型是自然语言处理（NLP）中用来发现文本中潜在语义结构或重要词组的一类统计模型。它们通常以大量文档构建，以保留每个文档的不同属性，同时也将每个文档的简短描述作为主题的独特组合。主题模型有助于机器学习中有用的基本任务，如文本摘要、文档相关性的确定、新颖性的检测以及分类。&emsp;&emsp;潜在狄利克雷分配（LDA）主题模型是由Blei等人首先在机器学习环境中应用的[18]。LDA的基本思想是文档可以表示为“潜在主题上的随机混合”，每个主题可以表示为单词上的概率分布。正是这种类型的主题模型在文本挖掘文献中得到了最广泛的应用。LDA模型以用户希望发现的文档和给定数量的主题t作为输入，并定义经常出现的t组词或n个语法。然后，每个文档都可以表示为t主题上的一个分布。 Literature Review&emsp;&emsp;社交媒体分析的研究倾向于关注文本，使用NLP、情感分析或意见挖掘等方法得出并支持研究结论，或者关注通过在线社区传播的内容[19–22]。这些方法已被证明对于理解或预测人类行为的许多方面都是有效的，但是它们却忽略了许多其他表达信号。另一方面，基于点击的反应在社交媒体研究中是一个相对未被充分利用的资源。快速绘制，现成的表达功能的示例在许多平台上变得越来越普遍，因此在过去几年中吸引了研究人员的大量关注。&emsp;&emsp;已经进行了一些研究，使用社交媒体数据来测量和理解情绪[23-27]。Tian等人[28]研究了Facebook用户用表情符号修改评论情绪的方式。他们瞄准了公共新闻页面上的帖子，比较了三种表达方式：自然语言、表情符号和反应。他们发现，通常表情符号的情感内容和反应是一致的，但在讽刺或礼貌的情况下，这两个渠道可以表达不同的含义。Krebs等人[29]使用从Facebook收集的客户满意度数据，使用卷积和递归神经网络（CNN和RNN）训练模型，并预测给定职位的反应分布。Basile等人[30]结合NLP和Facebook反应的情绪分析，建立一个回归模型，用来预测意大利媒体的新闻争议。&emsp;&emsp;在Facebook和其他社交媒体平台上，有几项关于社区建设、社交互动和身份确认的研究。Rohde等人[31]和Hewitt等人[32]是社会媒体数据如何用于在线研究社区间互动和身份形成的早期例子。Burke等人[33]研究发现，如果Facebook用户的朋友网络规模较小，联系更紧密，那么他们对社区成员的帖子的正面和负面反应都会更强烈。Thagard和Kroon[34]强调了情感共识在群体决策、社区凝聚力中的作用。他们的情感共识观念是建立在这样一种观念之上的：当所有党派成员都交流他们与每一种可能性相关联的效价时，群体就达成一致。作者认为，共识部分是通过理性的讨论和论证达成的，但我们过分强调了这一点的重要性，因为我们倾向于相信人类是理性的行动者。他们调查了心理学研究，发现群体行为更多地受到非语言交流的驱动，例如“面部表情，声音，姿势，和动作”。在努力达成共识的过程中，情绪上更强势的立场是“具有传染性的”，会在群体中传播，最终对结果产生最大的影响。&emsp;&emsp;Kumar等人[35]看到了Reddit上社区之间的冲突和对抗。它们由参与站点上不同论坛（即“subreddits”）的用户定义社区，每个社区都满足用户的特定兴趣，并由页面版主策划。这个社区定义是一个明确的空间，在这个空间里，成员经常访问并与其他成员互动，这个社区可以在Reddit的结构中很好的运行。Reza等人[36] 将这种类型的社区标记为显式的，在这个社区中，用户了解到他们是社区的成员，并且与社区中的其他成员进行交互的机会超过非成员。&emsp;&emsp;一些研究表明，一个人的情绪，如愤怒、悲伤、快乐和沮丧，在对他人的影响程度上是不同的。Rosenquist等人[37]使用纵向统计模型分析了弗雷明翰心脏研究[38]中12067人的社会网络，这是一项长期、持续的心血管队列研究，研究对象是马萨诸塞州弗雷明翰市的居民，目的是确定一个人的抑郁症状是否与其朋友、同事、兄弟姐妹、配偶和邻居有关。为了评估抑郁症状，研究人员使用了中心的流行病学量表。研究结果表明，在三个分离度的人群中可以发现一种关联，即从抑郁者的朋友到他们的朋友，再到他们的朋友。研究人员还研究了网络用户表现出的这些情绪的变化。Fan等人[39]在中国的微博网站Weibo上，使用了一个关于愤怒、快乐、厌恶和悲伤的多情感分类模型来确定这些情感之间的关系。利用皮尔逊相关和斯皮尔曼相关，他们发现不同的情绪有不同的相关性。他们的研究表明，用户之间的相关性是高愤怒和低悲伤情绪。&emsp;&emsp;Burnap等人的研究[40]不仅包括情绪分析，还包括用户先前党派支持预测2015年英国大选结果的细节。研究人员利用近1400万条推文训练了一个模型，并依靠从极端负面到极端正面的一系列信息来描述用户的情绪，他们预测工党将赢得大选。在类似的研究中，Vepsalainen等人。[41]研究了Facebook上的“Likes”如何被用来预测选举结果。他们使用Facebook的Graph API收集了270万个数据点，并使用绝对误差来衡量他们预测的准确性。在这项研究中，作者惊讶地发现“Likes”并不是选举结果的有力指标。在这项研究中，作者惊讶地发现“喜欢”并不是选举结果的有力指标。 MethodsThe dataset&emsp;&emsp;我们的数据集由通过Altmetric的在线数据库发现的文章组成。他们的数据库包含有关以各种语言和学科出版的数百万篇学术文章，研究报告和有关科学发现的新闻的信息。我们过滤了我们的目标文章，只针对那些已经在公共Facebook页面上分享了一次或多次的文章。我们进一步筛选了2017年发表的文章。选择今年完成了三个目标：（1） Facebook在2016年2月发布了反应[42]，因此我们看到的任何文章都必须在这段时间之后发布，才能获得关于这一功能的有意义的数据。（2）每当推出新功能时，用户都需要时间来学习如何使用它；Shah [43]发现，反应的使用率从2016年4月的所有互动的2.4％增加到2016年6月的5.8％，到2018年6月增加到所有互动的12.8％；到2019年初我们收集数据时，有足够大的用户群对该功能表示满意，以获得更多学术关注。(3)在我们开始收集数据时，已经过了足够的时间间隔，可以广泛分享文章并做出反应（15至30个月）。&emsp;&emsp;Altmetric的数据库提供了在公共Facebook页面上共享文章的URL。我们使用这些链接来查询Facebook的Graph API，以获取有关用户对帖子的反应的信息。此过程限制为每小时200个查询，每个单独的查询都会检索（1）基于点击的反应，（2）文章接收到的“重新共享”数量，以及（3）在公共页面上共享一份文章时包含的任何文本。有些文章被多次分享到许多不同的页面；对于这些，我们收集了每个帖子的信息，并将所有的反应汇总为总反应分数。我们没有收集用户在帖子中添加评论的信息，也没有收集“重新分享”一文的信息。我们的数据集中的文章共享范围在1到362之间。我们的数据集中文章获得的分享数的中位数是1。平均分享数为2.30，标准差为4.57。显然，文章的分享数的分配是偏右的——少数文章收到的分享数是平均分享数的很多倍。&emsp;&emsp;我们收集了149747篇科学文章的356664分享数的数据。大部分收集工作是在2019年3月至7月之间进行的。但是，对于本研究，我们感兴趣的是探索Facebook用户如何采用基于点击的反应。因此，我们将所看的文章仅限于那些收到五种特殊反应中一种或多种反应的文章。我们最终筛选的数据集包括33662篇文章，分享到178403个公共Facebook页面上，所有这些文章共收到6418053个基于点击的反应和2051299个“重新分享”。&emsp;&emsp;对于每一篇文章，我们的数据集包括：文章标题、文章摘要、文章发表日期、文章共享到的公共Facebook页面数以及每一类别的基于点击的反应数。它还记录了文章中的文字（如果有的话）。这里还有一些记录文章主题的功能：“主题”， 其中包括作者选择的与每篇文章相关的主题领域；“Scopus主题”，这是记录在Scopus数据库中每个文章条目中的主题领域；以及“出版商主题”，记录发表文章的期刊的主题领域。每篇文章的每个功能都可以包含一个，多个或不包含任何主题。&emsp;&emsp;在我们的数据收集过程中，我们非常小心地遵守Altmetric和Facebook关于如何以及为什么可以访问和使用他们的数据的规范。我们优先避免收集有关特定社交媒体用户的个人身份信息。我们的兴趣只是人们在社交媒体平台上与学术内容进行整体互动的方式，而不是特定用户的信仰或意见如何影响他们的行为。我们认识到，在某些情况下，识别信息可以从我们收集的一些数据中推断出来；但是，我们的数据收集方法并未针对任何可用于一致地识别个人用户的内容。 Feature analysis and transformation&emsp;&emsp;在概述我们如何转换和使用数据集中的特征来测量情绪的效价、多样性和强度之前，我们将首先描述我们在数据中发现的一些基本模式和关系，这些模式和关系为我们的决策提供了信息。找到适当的方式来赋予这个特征重要性，或者需要了解每个特征的含义以及特征之间的交互方式。对特征的更改必须谨慎而慎重，因为重要信息可能在转换过程中丢失或损坏。Feature analysis&emsp;&emsp;基于点击的反应在整个数据集中分布不均匀。图2a显示了数据集中每个反应类型的总数。我们看到“Likes”比其他任何反应都高出一个数量级。在这五种特殊反应中，“Love”和“Wow”是普遍存在的，而“Sad”和“Anger”等消极反应则不太常见。同样，表1显示了六个基于点击的反应和“重新共享”的描述性统计数据。我们可能假设Facebook用户更有可能对科学内容（或一般而言，对平台上的内容）做出积极反应，或者通过平台传播具有正价的科学内容。我们可能还认为，这些积极的反应更为常见，因为它们比消极的效价反应更容易被用户接触到。尽管这些假设可能具有一定的分量，但我们可以通过仔细检查反应的使用情况来了解更多信息。在查看图2a时，我们将考虑三个主要因素：（1）Facebook发布反应的历史时间线，（2）Facebook用户界面的布局，以及（3）术语“Like”、“Love”和“Wow”在语义上的接近性。 &emsp;&emsp;首先，“Like”是Facebook最初的反应。在2004年到2016年间，“Like”和“Reshare”是平台上唯一可用的基于点击的反应。到2016年发布这五个特别的反应时，用户已经习惯了使用“Likes”来回应各种内容（例如，正价和负价的帖子）。因此，即使有了更广泛的反应选项，用户仍然更有可能采用“Likes”的方式。其次，通过将鼠标悬停在“Likes”按钮上以打开特殊反应选项板，可以在用户界面中找到五个特殊反应。“Sad”和“Anger”位于反应选项的最右侧，因此用户需要尽最大的努力和意愿进行选择，而“Likes”，“Love”，“Laughter”和“Wow”的反应则归类于反应选项的左侧。用户点击“Like”的容易程度，以及这种反应与“Love”和“Wow”的空间关联，可能解释了这些反应在我们的数据集中普遍性。这个论点是有说服力的，但只能扩展到目前为止。&emsp;&emsp;最后，比起其他任何反应，“Like”一词在语义上与“Love”和“Wow”更相关（如惊奇或敬畏）。此外，代表“Like”的图标是竖起大拇指，表示支持和同意，通常表示积极的情绪；它的积极性可以与“Love”（由一刻心代表）和“Wow”（由一张惊讶的脸代表）联系更紧密。这些关联至少在某种程度上解释了该特性的使用。&emsp;&emsp;但是，我们应该注意不要将语义相关性扩展得太远。例如，我们可能会惊讶地发现朋友关于亲戚或个人过世之事的帖子收到了“Likes”； 显然，这些回答并不是要表明他或她的朋友们对目前的情况感到高兴，而是他们表达了更类似于团结或同情的东西。这个例子表明“Like”反应的使用并不一定与它的语义有关。表2显示了我们的数据集中包含每个反应类型的文章的比例。表3显示了在我们的数据集中，每个配对中至少收到两个反应之一的文章的比例，为这种效果提供了证据。我们可以通过比较带有“Likes”和其他反应(表3第一行)的文章与表2中值的比例来判断，“Likes”几乎在任何时候都与所有其他反应配对，这五个特殊的反应都是如此。图2b中的相关性表明“Likes”与“Love”和“Wow”反应共同变化，但这并不意味着它们也不与其他反应类型配对。&emsp;&emsp;由于“Love”和“Wow”与“Like”反应有着语义和物理上的相似性，我们不仅希望看到它们也被更频繁地使用，而且希望这些特征的使用能够显示出正相关。图2b显示了特征之间的Spearman（斯皮尔曼）相关系数。“Like”、“Love”和“Wow”之间有很高的正相关。我们的直觉是，在我们看到“Likes”程度增加的同时，我们也期望“Love”或“Wow”反应增加，这也得到了我们数据的支持。消极的反应“Sad”和“Anger”也是高度相关的。“Reshares”和“Like”、“Love”和“Wow”反应之间的高度正相关使我们相信积极的内容在Facebook上被更广泛的分享和反应，这一发现与论文[39]等研究的结论（负面情绪会在社交网络中产生更大的互动和分散）相悖。&emsp;&emsp;正是由于这些原因，我们不应低估“Anger”或“Sad”等不太常见反应的出现。它们在文章上的出现代表用户有更多的意图和努力以提供特定的响应。因为积极的反应是预期的反应模式，并且由于消极的反应需要用户更多的努力才能应用，所以我们决定用我们对看到该类型反应的期望的反比来衡量不同类型的反应。 Feature transformation&emsp;&emsp;我们数据集中的文章的反应并不相同。在一个页面上分享一篇文章可能会导致数千条回复，而在另一个页面上分享同一篇文章可能根本没有任何回复。反应的数量可能是一个帖子或文章引起了用户强烈反响的信号，但是很难解释上下文，例如看到该帖子的人数。有多少用户关注公共页面因页面而异，因此每页上文章的可见性也会有所不同。也很难解释Facebook将帖子传播到用户新闻提要中的算法。&emsp;&emsp;我们对基于点击的反应进行加权的方法是基于我们期望在任何给定文章中找到它们的概率。权重是通过一种与词频-逆文本频率指数（TF-IDF）相关的方法确定的，这是一种在当前许多信息检索和推荐系统中使用的一系列文档中设置术语相对重要性的方法。我们将加权程序称为“反应频率-逆文本频率（RF-IDF）。&emsp;&emsp;我们将每篇文章的原始反应计数更改为文章收到的所有基于点击的反应的比例。例如，如果一篇文章收到了6个“Likes”、1个“Love”和2个“Wow”的反应，我们会将这些值转换为6/（6+1+2）“Likes”、1/9“Love”和2/9“Wow”的反应。然后我们对数缩放这些值。这个转换的结果给出了反应频率（RF_(ⅆ_r )）（方程式1），其中ⅆ_r是给定文档d接收到的特定反应r的计数，R是所有六个基于点击的反应的列表。&emsp;&emsp;接下来，我们需要奖励罕见的反应，惩罚常见的反应，并为每种反应类型确定适当的权重。为此，我们发现了一种给定的反应将被应用于一个随机文章的概率，这是通过将数据集中具有该反应类型的文章数除以数据集中的文章数而得出的。逆文本频率（IDF）是该概率的自然对数。这个值给出了每种反应类型的IDF（方程式2），其中|D|是数据集中的文章数，|D_r |是数据集中接收到特定反应r的文章数。&emsp;&emsp;最后，我们通过将每种反应类型的对数比例乘以该种反应的IDF来计算RF-IDF，如等式3所示。 Metrics of emotional diversity and intensity&emsp;&emsp;通过我们转换的基于点击的反应，我们开发了指标来衡量用户对数据集中文章的反应的效价，强度和多样性。效价是这三个指标中最简单的。因为它代表了一个反应趋向的积极或消极的方向，所以我们必须确定反应中编码的积极和消极情绪的信号。“Love”和“Anger”是相对直截了当的，分别具有正价和负价。这种“Sad”的反应可以用来表达对一个经历了一些困难的人的同情或声援，但在我们正在研究的一组帖子中，用户不太可能一直在自己的帖子或研究中分享个人经验，从而激发这种同情的反应。图2显示了“Anger”和“Sad”之间非常高的相关系数。事实上，这对特征在所有特征对中具有最高的相关性。这为这两种反应具有同一个效价的观点提供了证据。&emsp;&emsp;为了确定每篇文章的效价，我们检查了其“ Love”反应的值是否大于其“ Sad”和“ Anger”反应的值，如等式4所示。接下来，我们计算数据集中每一篇文章的反应强度。在构思我们的指标时，我们首先观察到，当对Facebook上的任何帖子提供基于点击的反应时，每个用户都会得到他们提供的一个准确的反应，其中不包括已经“Liked”或提供五个特殊反应之一的用户选择了的“Reshares”。用户通过选择一个特殊的反应而不是默认的“Like”，展示了对更具体反应的渴望。我们把这种意图和努力理解为一种强烈的情绪反应的标志。考虑到这一点，我们认为强度是五种特殊反应与六种点击反应之和的比率。我们首先对给定文档d的所有反应进行求和，如等式5所示。然后我们总结了五种特殊的反应，并将它们除以总的点击反应，如方程式6所示。这将我们的强度指标限制在[0,1]之间，其中0表示收到“Like”反应但没有其他反应的文章，而1表示仅收到特殊反应的文章的分数；以这种方式限定我们的指标有助于文章之间的比较。我们设计的强度指标，对获得低反应数量的帖子敏感。对我们而言，重要的是，无需依靠纯粹的反应量，就能够确定收到强烈的情绪信号的帖子。最后，我们开发了一个指标来衡量用户对每一篇文章的反应的多样性。多样性衡量给定文章中有多少不同的特殊反应类型，以及这些反应的平均分布情况。我们忽略了对我们多样性衡量的“Like”反应。如上所述，这种反应在使用上是相当灵活的，并且依赖于上下文的意义。我们使用JS散度距离（JSD）作为度量的基础，JSD使用熵和Kullback-Leibler散度来度量两个概率分布之间的差异。JSD是通过对JS散度得分的平方根求出的。我们首选JS距离而不是JS散度，因为前者是真实的距离度量标准，并且已证明可以满足三角形不等式。后一个属性提高了我们比较多篇文章的结果的能力。我们更喜欢JSD而不是Kullback-Leibler散度，因为后者没有上界，使得比较不同的观测值变得困难。&emsp;&emsp;我们假定所能观察到的反应类型的最高多样性是类型的均匀分布，其中每个反应的比例相等，并记录了这种均匀分布与我们所观察到的分布之间的JSD。JSD是一个（0,1）有界值，其中（在我们的例子中）0表示观察到的分布是均匀的，1表示观察到的分布与均匀分布相差很大（即只有一种特殊反应）。其中P和Q是两个分布，M=(P+Q)/2,KLD(P||Q)是Kullback-Leibler散度。由于代表一篇文章所能收到的最大多样性的均匀分布将产生0，因此我们采用补足值：其中θ_d是给定文章d的五个特殊反应的分布，而U {0,1}是[0,1]的离散均匀分布。&emsp;&emsp;我们的度量标准被设计为组合，以便在文章之间进行进一步的比较。例如，多样性评估一篇文章中出现了多少不同的反应，但不评估出现了多少反应，也不评估五个特殊反应占所有基于点击的反应的比例。正如方程式9所示，将多样性指标与强度指标相乘，我们能够识别收到强烈反应以及存在许多不同情绪的反应的文章。&emsp;&emsp;我们还可以将效价和强度得分相结合以产生极性得分，该极性得分报告了响应的强度和方向（方程式10） Training a topic model&emsp;&emsp;我们的兴趣不仅仅在于个人对特定科学文章的反应：我们希望利用我们的数据更好地理解对科学领域的总体情感反应。为此，我们希望以尽可能合乎逻辑的方式对论文进行分组。我们最初考虑使用与Altmetric数据集中的每一篇文章相关联的“Scopus subject”标记，但是很多文章都缺少这个特性。此外，回复帖子的用户不一定要点击链接打开文章并在回复之前阅读内容，如[21]所示。接下来，用户会对他们直接遇到的内容做出反应：Facebook的帖子。因此，我们希望找到方法来尽可能多地保留帖子文本的详细信息。按照这种推理，我们在每篇文章的文章共享所包含的文本上训练了主题模型。&emsp;&emsp;我们在构建LDA主题模型时采取了以下步骤。我们首先将与某篇文章分享的每个文本合并在一起。每一篇文章都可以分享很多次，因此我们的“文本”的长度变化很大。LDA主题模型是处理此类数据的特别强大的工具[18]。这些帖子也可以使用多种语言，所以我们只保留了英文文本。我们清理了文本，删除了超链接、标点符号、电子邮件地址和标签。然后，我们从标记的文本中创建了二元和三元（分别是两个单词和三个单词的常见分组）。我们删除了“ the”和“ and”之类的停用词，并对每个词进行了词形去除，这涉及到删除词尾变化以将每个词转换为字典形式（例如，使复数名词成为单数，将动词更改为不定式）。最后，我们删除了少于15个文档中出现的单词和超过一半文档中出现的单词。结果就是我们用来训练模型的语料库。&emsp;&emsp;我们使用了Python的Gensim库中的LDA模型[44]。选择一个模型识别的主题数t可能会很耗时。这个数字可能会根据研究者对模型的目标或数据的形式而改变。我们的目标是可解释性：我们希望能够很容易地理解给定的主题是关于什么的，并且能够相对容易地区分一个主题和另一个主题。我们还希望主题的数量反映出我们希望在数据集中看到的字段的数量。在我们的数据集中，大约有30种不同的Scopus主题标签（例如，物理，生物化学，计算机科学）被应用于文章。我们推断，将t设置在15到40之间可以适当表示我们期望在集合中看到的字段。&emsp;&emsp;我们训练了七个LDA模型，每个模型在15≤t≤50范围内具有不同的值。我们基于主题一致性得分（CS）比较了我们的模型，CS(coherence scores)是一种测试每个主题中最具代表性的单词之间语义相似度的指标。较高的CS分数通常表示模型具有更好的识别不同主题的能力。在我们的模型中，一致性得分最高的是cs（t=20）=0.515。然后，我们使用t = 20的模型将帖子文本转换为主题分布。LDA返回给定文档中出现每个主题的概率，因此我们选择出现概率最高的主题来表示每一篇文章。例如，如果文档x的主题分布为[t1=0.7，t2=0.3]，我们会将其标记为表示主题t1。表4显示：（1）发现的20个主题，（2）每个主题最具代表性的文章数，（3）每个主题十个最具代表性的词。 Kolmogorov-Smirnov test&emsp;&emsp;我们感兴趣的是测试属于给定主题的文章子集的度量值是否与其他文章中的值存在显著差异。为此，我们使用了两个样本的柯尔莫诺夫-斯米尔诺夫检验（KS检验）。KS检验是对两个连续的一维概率分布的非参数统计检验。它不对这两个分布的正态性做出任何假设，并测试这两个分布是否从是相同的总体（或具有相同分布的总体）中抽样的。KS检验给出两个值：（1）KS统计量，该统计量是从两个分布的累积分布之间的最大距离（称为最高点）得出的，以及（2）表示观测到的KS统计量显著性的p值。这个p值回答的问题可以表述如下：如果我们假设这两个样本来自同一个总体，那么观察这些分布之间给定距离的可能性有多大？一个小的p值（p&lt;0.05）表明从同一群体的样本中看到这种差异的概率很低，并且我们可以拒绝原假设，在这种情况下，原假设表明两个样本来自同一群体。我们通过以下方式制定假设： 其中P和Q是用作KS检验输入的两个样本，H0是原假设，其中两个样本来自相同的总体，H1代表我们拒绝原假设的情况。&emsp;&emsp;我们的测试设置如下。（1） 我们选择用两个标准来执行测试：多样性和极性(diversity、polarity)。（2）我们选择了几个主题，我们假设这些指标的分布与本文的其他部分明显不同。我们选择专题1（政府）、8（疫苗）、16（性别）和20（遗传学）来测试显著的多样性得分(diversity scores)，专题8（疫苗）、10（农业/环境科学）、13（药物和酒精）和14（气候变化）来测试极性得分(polarity scores)。（3）我们将拒绝零假设所需的显著性水平设为α=0.05。KS检验产生一个双尾p值，因此只有当p&lt;0.025或p&gt;0.975时，我们才能拒绝H0，否则不能拒绝。（4）对于每个测试，我们将数据分成两组：代表给定主题的文章和所有其他文章。（5）然后，我们用给定样本上每个度量的分布进行KS检验。 Resultd and Discussion&emsp;&emsp;图3a显示了文章沿两个特征轴的分布：x轴上的divint index和y轴上的对数缩放的“ Reshare”计数。我们发现，大多数文章的divint index数值在0.3-0.4之间（μ=0.322，med.=0.313，SD=0.117）和相对较少的“Reshares”（此特征的统计数据如表1所示）。随着文章的divint index值的增加，文章被“Reshared”的可能性也略有增加。此关系通过图中用红色绘制的回归线显示。&emsp;&emsp;polarity数值的分布如图3b所示。尽管有更多的文章获得了正极性得分(positive polarity score)，但负极性得分(negative polarity score)更接近于极值。大多数文章（80％）都得到了正价，但在任何范围内的大多数论文都集中在-1左右（意思就是在任何范围内，在-1处的文章数较多）。大约有3250篇文章的极性数值(polarity score)为-1，而只有1250篇文章的极性数值(polarity score)为1。文章在[0.6,0]范围内显著减少。这种行为不应该让我们感到惊讶：我们在图2中看到，“Likes”与“Sad”或“Anger”反应无关，但它们与“Love”反应高度相关。“Love”反应的增加往往伴随着“Like”反应的增加而发生，必然会降低这些事例的强度的数值。另一方面，增加的“Sad”或“Anger”反应并不倾向于伴随增加的“Like”反应，从而将强度得分推高。&emsp;&emsp;我们发现，Facebook用户通常对研究的反应是积极的，这与其他研究结果一致，即人们更有可能分享积极的内容，而不是消极的内容[45]; 但我们的研究结果也表明，当人们有负面反应时，他们的反应往往会更强烈，这可以从相对缺乏处于中等负面范围的文章（-0.6,0]和大量数值为-1的论文中看出。Besley和Nisbet [46]发现，在接受科学发现时，科学家认为公众是“情感的”（而不是“理性的”）和“容易恐惧的”。 在我们的数据集中，对文章表达的积极情绪反应的突出表明，对科学的“情绪”反应通常是支持的。由于消极反应或批评对特定的人来说更为突出[7,12]，所以科学家们更容易注意到这些消极反应，尤其是在这些反应更为强烈的情况下。可能是这些消极但强烈的反应不成比例地塑造了科学家对公众的印象。&emsp;&emsp;KS测试结果见表5。对于多样性数值(diversity scores)，主题16和主题20与数据集的其余部分有显著的偏差。对于极性数值(polarity scores)，只有主题10显示出显著的偏差，足以拒绝原假设。已知使用相对较小的样本进行测试时，KS检验更有可能导致无法拒绝原假设。主题16（性别）只有17篇文章代表样本，因此我们特别惊讶地发现，在如此小的样本量下，有如此显著的结果。&emsp;&emsp;我们也为未能拒绝原假设的情况感到惊讶，特别是针对主题8(疫苗)的任何一个度量。人们对疫苗研究的负面情绪反应广为人知，并在社交媒体平台上广为流传，但我们的数据表明，对该主题的负面反应并未明显偏离使用者对整个研究的反应。可能是这样的，因为我们正在通过Altmetric的数据库跟踪科学文章，我们只看到那些已经接受该领域科学发现的人对疫苗研究的反应。要想找到不同意见，我们就必须把目光放在科学研究领域之外。&emsp;&emsp;我们在图2a中看到的反应分布可能是我们选择的研究领域的结果。例如，如果我们研究主要新闻机构的文章，我们可能会发现负面情绪有更高的表现。在针对学术研究的份额时，我们选择了一个通常被认为是情感中立的领域，尽管它并非完全没有争议的话题。但即使是查看流行的新闻来源，我们也假设负面反应会因为同样的原因(它们与“Likes”的高度相关，以及用户选择它们所需要的额外工作量)出现在正面反应之后。&emsp;&emsp;许多社交媒体研究本质上是预测性的。从事这一领域工作的人开发的模型经常使用altmetrics的特征来预测哪些研究成果将是重要的，某个领域中的新星是谁[47]，或者发现可能被忽略的令人惊讶的文章[48]。本文提出的特征转换与生成方法也可用于预测任务。预测模型还依赖于对用于训练和测试的数据的深入了解；因此，我们在这里提出的分析可以作为其他有兴趣利用社交媒体数据预测科学成果的研究人员的基础。&emsp;&emsp;我们使用我们的度量标准来确定对科学领域的总体情绪反应，而不是对单个文章的情绪反应，但是我们的方法也可以用于单个帖子。内容管理者或平台可能希望快速高效地找到负面或有争议的内容，以改善用户体验。它还可以帮助科学家和研究人员更好地理解他们在更广泛的社会中塑造情感动力的作用。我们的度量标准提供了一种识别对稀疏反应曲线敏感的材料的方法，以便在必要时可以快速有效地做出适当的反应。 Conclusion and Future Work&emsp;&emsp;在本文中，我们提出了一种基于点击的反应分析的新方法。我们通过分析Facebook对发布在公共页面上的学术文章的反应数据集，改进了这种方法，并将其用于探索用户对科学主题的情绪反应。我们提出了一种根据TF-IDF统计数据转换基于点击反应的分析方法。我们借鉴了行为心理学的概念，开发了一些度量方法，用这些转换后的特征来衡量用户的总体行为。最后，我们使用LDA主题建模和统计测试来发现科学主题令人惊讶的情绪反应。&emsp;&emsp;寻找情绪多样性或强烈强度的实例有助于理解社区动态。冲突和分裂可能是群体分裂的断层线，找到识别它们的方法并在必要时进行干预可以提高成员的凝聚力。这些划分也使我们能够意识到许多在线平台上存在的多样性。根据本文的贡献，我们计划使用社会网络分析来更好地了解情绪是如何在科学界传播的。我们将调查情绪如何影响网上虚假信息和虚假信息的散布，以及它们在向非专家有效传达调查结果方面所扮演的角色。探索这些及其他相关问题最终将导致更好的研究结果，并将增进我们对情绪在塑造科学家和公众之间的交流中所产生影响的理解。 AcknowledgmentsThis work was partially supported by Argonne National Laboratory under grant number G2A62716. References略！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[安装思科模拟器（Cisco Packet Tracer）]]></title>
      <url>%2F2017%2F12%2F08%2F%E5%AE%89%E8%A3%85%E6%80%9D%E7%A7%91%E6%A8%A1%E6%8B%9F%E5%99%A8%EF%BC%88Cisco-Packet-Tracer%EF%BC%89%2F</url>
      <content type="text"><![CDATA[简介 软件介绍Packet Tracer 是由Cisco公司发布的一个辅助学习工具，为学习CCNA课程的网络初学者去设计、配置、排除网络故障提供了网络模拟环境。学生可在软件的图形用户界面上直接使用拖曳方法建立网络拓扑，软件中实现的IOS子集允许学生配置设备；并可提供数据包在网络中行进的详细处理过程，观察网络实时运行情况。 软件安装包 自己百度安装包。 在这个百度云盘下载：链接: https://pan.baidu.com/s/1hsEinsC 密码: jbkf 安装步骤 下载完成后，直接双击PacketTracer60_Build45_setup_no_tutorials应用程序，进行安装，单击next下一步。 选择第一个选项“I accept the agreement”，单击next下一步 单击“Brwose…”选择所要安装的位置，单击next下一步，这一步需要注意的是，装在一个你经常装软件的文件夹里，可以是中文的路径。 选择Install选项，安装思科模拟器。 等待进度条走完后，若弹出如下窗口，点击“确定”。 默认选项为安装完成后立即启动packetracer，这里可以勾选，也可以不勾选。 汉化思科模拟器（Cisco Packet Tracer） 将Chinese.ptl文件复制粘贴到安装的目录下languages文件夹下，如下图所示： 现在双击桌面的Cisco Packet Tracer的应用程序，启动思科模拟器。 打开后，点击左上角的options选项，单机里面的preferences选项或直接在打开的界面处，按下快捷键Ctrl+R，快速打开。如下图所示： 在打开的窗口中，在选择语言的地方，选择Chinese.ptl，单击change language。 弹出如下窗口，单击“OK”。 最后，重新启动该程序，就可以了。 最近访客]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Thymeleaf layout 布局]]></title>
      <url>%2F2017%2F07%2F19%2FThymeleaf-layout-%E5%B8%83%E5%B1%80%2F</url>
      <content type="text"><![CDATA[简介 Thymeleaf是现代化服务器端的Java模板引擎，不同与JSP和FreeMarker，Thymeleaf的语法更加接近HTML，并且也有不错的扩展性。 详细资料可以浏览官网(http://www.thymeleaf.org/)。本文主要介绍Thymeleaf模板的使用说明： thymeleaf的layout常用的有两种方式用法： 日常开发中，我们经常会将导航栏，页尾，菜单等部分提取成模板供其它页面使用。 fragment,include和replace的运用：Thymeleaf的多种引入方式 · th:insert 3.0+版本新加的 · th:replace 2.0+ 3.0+都可用 · th:include 这个在3.0版本已经不建议使用 将页面里的每个部分都分成 块 -&gt; fragment 使用 th:include 和 th:replace 来引入页面 在components下新建一个header.html和footer.html 再在templates下新建一个components文件夹 components中header的fragment: 12345678&lt;!-- components/header.html --&gt; &lt;header th:fragment=&quot;header&quot;&gt; &lt;ul&gt; &lt;li&gt;news&lt;/li&gt; &lt;li&gt;blog&lt;/li&gt; &lt;li&gt;post&lt;/li&gt; &lt;/ul&gt; &lt;/header&gt; components中footer的fragment: 1234&lt;!-- components/footer.html --&gt;&lt;header th:fragment=&quot;footer&quot;&gt; &lt;div&gt;i am footer.&lt;/div&gt;&lt;/header&gt; 主页index(用include):1234567891011121314&lt;!-- index.html --&gt; &lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot;/&gt; &lt;title&gt;demo&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;div th:include=&quot;components/header :: header&quot;&gt;&lt;/div&gt; &lt;div class=&quot;container&quot;&gt; &lt;h1&gt;hello world&lt;/h1&gt; &lt;/div&gt; &lt;div th:include=&quot;components/footer :: footer&quot;&gt;&lt;/div&gt; &lt;/body&gt; &lt;/html&gt; 主页index(用replace) 12345678910111213141516171819202122&lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot;/&gt; &lt;title&gt;demo&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;div th:replace=&quot;components/header :: header&quot;&gt; &lt;!-- 使用th:replace进来的header.html会替换下面的这个header --&gt; &lt;header&gt; &lt;ul&gt; &lt;li&gt;static - news&lt;/li&gt; &lt;li&gt;static - blog&lt;/li&gt; &lt;li&gt;static - post&lt;/li&gt; &lt;/ul&gt; &lt;/header&gt; &lt;/div&gt; &lt;div class=&quot;container&quot;&gt; &lt;h1&gt;hello world&lt;/h1&gt; &lt;/div&gt; &lt;div th:include=&quot;components/footer :: footer&quot;&gt;&lt;/div&gt; &lt;/body&gt;&lt;/html&gt; insert, include和replace的区别：12345&lt;!-- 要被引用的html块 --&gt;-----------------------------&lt;footer th:fragment=&quot;footer&quot;&gt; 2017 Copyright © TonyNYL &lt;/footer&gt; 123456789&lt;!-- 引用html段 --&gt; -----------------------------------------&lt;body&gt; &lt;div th:insert=&quot;footer :: footer&quot;&gt;&lt;/div&gt; ----------------------------------------- &lt;div th:replace=&quot;footer :: footer&quot;&gt;&lt;/div&gt; ----------------------------------------- &lt;div th:include=&quot;footer :: footer&quot;&gt;&lt;/div&gt;&lt;/body&gt; 123456789101112131415161718192021&lt;!-- 最终形成结果 --&gt; ---------------------------------------------------------&lt;body&gt; &lt;!-- th:insert，div tag内部插入html块 --&gt; &lt;div&gt; &lt;footer&gt; 2017 Copyright © TonyNYL &lt;/footer&gt; &lt;/div&gt; --------------------------------------------------------- &lt;!-- th:replace，使用html块直接替换 div tag --&gt; &lt;footer&gt; 2017 Copyright © TonyNYL &lt;/footer&gt; --------------------------------------------------------- &lt;!-- th:include，div tag内部插入html块（仅保留段子元素的内容） --&gt; &lt;!-- 仔细对比 th:insert 与 th:include的不同 --&gt; &lt;div&gt; 2017 Copyright © TonyNYL &lt;/div&gt;&lt;/body&gt; 用html中的id属性代替fragment定义的名称：1234&lt;!--footer.html块 --&gt;&lt;div id=&quot;footer&quot;&gt; 2017 Copyright © TonyNYL&lt;/div&gt; 12345678&lt;!-- 引用上面的html块 --&gt;&lt;!-- :: 前面是html名称相对路径，不需要写后缀(.html)；后面是html tag的id，id前需要加 #，这是3.0+的写法 --&gt;&lt;div th:insert=&quot;~&#123;footer :: #footer&#125;&quot;&gt;&lt;/div&gt;------------------------------------------------------&lt;!-- 2.0+要这么写 --&gt;&lt;div th:insert=&quot;footer :: #footer&quot;&gt;&lt;/div&gt; layout:decorator的运用 在layouts的文件夹中新建一个layout.html作为模板 123456789101112&lt;!-- layout/layout.html --&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot;/&gt; &lt;title&gt;demo&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;div th:include=&quot;components/header :: header&quot;&gt;&lt;/div&gt; &lt;div layout:fragment=&quot;content&quot;&gt;&lt;/div&gt; &lt;div th:include=&quot;components/footer :: footer&quot;&gt;&lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 再在需要改布局模板的页面加入layout.html 12345678910&lt;!-- index.html --&gt;&lt;html layout:decorator=&quot;layout/layout&quot;&gt; &lt;head&gt; &lt;/head&gt; &lt;body&gt; &lt;div layout:fragment=&quot;content&quot;&gt; &lt;h2&gt;hello TonyNYL!&lt;/h2&gt; &lt;/div&gt; &lt;/body&gt;&lt;/html&gt; layout模板的布局传入的属性值 首先，定义一个属性样式 123.active &#123; background-color: white;&#125; 1234567&lt;header th:fragment=&quot;header (tab)&quot;&gt; &lt;ul&gt; &lt;li&gt;&lt;span th:class=&quot;$&#123;tab eq &apos;home&apos;&#125; ? active&quot;&gt;home&lt;/span&gt;&lt;/li&gt; &lt;li&gt;&lt;span th:class=&quot;$&#123;tab eq &apos;blog&apos;&#125; ? active&quot;&gt;blog&lt;/span&gt;&lt;/li&gt; &lt;li&gt;&lt;span th:class=&quot;$&#123;tab eq &apos;news&apos;&#125; ? active&quot;&gt;news&lt;/span&gt;&lt;/li&gt; &lt;/ul&gt;&lt;/header&gt; 在需要的地方调用这个方法1&lt;div th:include=&quot;components/header :: header(tab=&apos;blog&apos;)&quot;&gt;&lt;/div&gt; 最近访客]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[线性表]]></title>
      <url>%2F2017%2F04%2F27%2F%E7%BA%BF%E6%80%A7%E8%A1%A8%2F</url>
      <content type="text"><![CDATA[简介 什么是线性表？线性表是一种线性结构。线性结构的特点是数据元素之间是一种线性关系，数据元素“一个接一个的排列”。在一个线性表中数据元素的类型是相同的，或者说线性表是由同一类型的数据元素构成的线性结构。在实际问题中线性表的例子是很多的，如学生情况信息表是一个线性表：表中数据元素的类型为学生类型; 一个字符串也是一个线性表：表中数据元素的类型为字符型，等等。 线性结构的特点为在数据元素的非空有限集中 集合中存在唯一的一个“第一元素” 集合中存在唯一的一个“最后元素” 除最后元素在外，具有唯一的后继 除第一元素之外，均有唯一的后继 线性表的类型定义介绍 数据表是最常用且最简单的一种数据结构。 在稍复杂的线性表中，一个数据元素可以由若干个数据项（item）。在这种情况下，常把数据元素成为记录（record）,含大量记录的线性表又称为文件（file）。 线性表定义如下：线性表是具有相同数据类型的n(n&gt;=0)个数据元素的有限序列，通常记为： (a1，a2，… ai-1，ai，ai+1，…an) 其中n为表长， n＝0 时称为空表表中相邻元素之间存在着顺序关系。将ai-1 称为ai 的直接前趋，ai+1 称为ai 的直接后继。就是说：对于ai，当i=2，…，n 时，有且仅有一个直接前趋ai-1.，当i=1，2，…，n-1 时，有且仅有一个直接后继ai+1，而a1 是表中第一个元素，它没有前趋，an 是最后一个元素无后继。 抽象数据类型线性表的定义 12345678910111213141516171819202122232425262728293031323334353637383940ADT List &#123; 数据对象：D = &#123;ai|ai∈EleamSet,i = 1,2,...,n,n&gt;=0&#125; 数据关系：R1 = &#123;&lt;ai-1,ai&gt;|ai-1,ai∈D,i = 2,...,n&#125; 基本操作： InitList (&amp;L); 操作结果：构造一个空线性表L DestroyList(&amp;L); 初始条件：线性表L已存在 操作结果：销毁线性表L ClearList(&amp;L); 初始条件：线性表L已存在 操作结果：将L重置为空表 ListEmpty(L); 初始条件：线性表L已存在 操作结果：判断若存在的表L为空表，返回TRUE，否则返回FALSE Listlength(L); 初始条件：线性表L已存在 操作结果：返回线性表L中的数据元素个数 GetElem(L,i,&amp;e); 初始条件：线性表L已存在，1&lt;=i&lt;=ListLength(L) 操作结果：用e返回L中第i个数据元素的值 LocateElem(L,e,compare()); 初始条件：线性表L已存在,compare()是数据元素判定函数 操作结果：返回l中第一个与e满足关系compare（）的元素的位序。若这样的数据元素不存在，则返回值为0 PriorElem(L,cur_e,&amp;pre_e); 初始条件：线性表L已存在 操作结果：若cur_e是L的数据元素（不是第一个），则用pre_e返回它的前驱，否则操作失败，pre_e无定义 NextElem(L,cur_e,&amp;next_e); 初始条件：线性表L已存在 操作结果：若cur_e是L的数据元素（不是最后一个），则用next_e返回它的后继，否则操作失败，next_e无定义 ListInsert(&amp;L,i,e); 初始条件：线性表L已存在，1&lt;=i&lt;=ListLength(L)+1 操作结果：在L的第i个位置之前插入新的数据元素e，L的长度加1 ListDelete(&amp;L,i,&amp;e); 初始条件：线性表L已存在且非空 操作结果：删除L的第i个数据元素，并用e返回其值，L的长度减1 ListTraverse(L,vist()); 初始条件：线性表L已存在 操作结果：依次对L的每个数据元素调用vist()。一旦visit()失败，则操作失败 &#125;ADT List 合并线性表LA和LB假设利用两个线性表LA和LB分别表示两个集合A和B（即线性表中的数据元素即为集合中的成员），现要求一个新的集合A = A∪B。操作：扩大线性表LA，将存在于线性表LB中而不存在线性表LA中的数据元素插入到线性表LA中去。只要从线性表LB中依次取得每个数据元素，并依值在线性表LA中进行查访，若不存在，则插之。算法描述如下： 123456789void union(List &amp;La,List Lb)&#123; //将所有在线性表Lb中但不在La中的数据元素插入到La中 La_len = ListLength(La);Lb_len = ListLength(Lb);//求线性表的长度 for(i = 1;i &lt;= Lb_len;i++)&#123; GetElem(Lb,i,e); if(!LocateElem(La,e,equal)) ListInsert(La,++La_len,e);//La中不存在和e相同的数据元素，则插入之 &#125; &#125;//union 该程序的时间复杂度为O( ListLength(La)* ListLength(Lb)) 合并LA和LB为新的线性表LC已知线性表LA和LB中的数据元素按非递减有序排列，现要求将LA和LB归并为一个新的线性表LC，且LC中的数据元素仍按非递减有序排列。基本算法如下： 123456789101112131415161718192021222324252627void MergeList(List La,List Lb,List &amp;Lc)&#123; //已知线性表LA和LB中的数据元素按非递减有序排列 //归并La和Lb得到新的线性表Lc,Lc的数据元素也非递减有序排列 InitList(Lc); i = j = 1; k = 0; La_len = ListLength(La);Lb_len = ListLength(Lb);//求线性表的长度 while((i&lt;=La_len) &amp;&amp; (j&lt;=Lb_len))&#123;//La和Lb均非空 GetElem(La,i,ai); GetElem(Lb,j,bj); if(ai &lt;= bj)&#123; ListInsert(Lc,++k,ai); ++i; &#125;else&#123; ListInsert(Lc,++k,bj); ++j; &#125; &#125; while(i &lt;= La_len)&#123; GetElem(La,i++,ai); ListInsert(Lc,++k,ai); &#125; while(i &lt;= Lb_len)&#123; GetElem(Lb,j++,bj); ListInsert(Lc,++k,bj); &#125;&#125;//MergeList 该程序的时间复杂度为O(ListLength(La)+ ListLength(Lb)) 线性表的顺序表示和实现线性表的顺序存储 线性表的顺序表示指的是用一组地址连续的存储单元依次存储线性表的数据元素。 假设线性表的每个元素需占用L个存储单元，并以所占的第一个单元的存储地址作为数据元素的存储位置。则线性表中第i+1个数据元素的存储位置LOC(ai+1)和第i个数据元素的存储位置LOC(ai)之间满足下列关系：LOC(ai+1) = LOC(ai) + L一般来说，线性表的第i个数据元素ai的存储位置为LOC(ai) = LOC(a1) + (i-1)*L式中LOC(ai)是线性表的第一个数据元素a1的存储位置，通常称做线性表的起始位置或基地址。 线性表的这种（第二条）机内表示称作线性表的顺序存储结构或顺序映像，通常，称这种存储结构的线性表为顺序表。 线性表的顺序存储结构示意图如下: 线性表的顺序表示与实现代码 c语言动态分配的一维数组 12345678// --------线性表的动态分配顺序存储结构--------#define LIST_INIT_SIZE 100 // 线性表存储空间的初始分配量#define LISTINCREMENT 10 // 线性表存储空间的分配增量typedef struct &#123; ElemType *elem; // 数据元素的地址 int length; // 当前长度 int listsize;//当前分配的存储容量(以sizeof(ElemType)为单位)&#125; 线性表顺序表示操作实例代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200/*** *Arrlist.h *Purpose: * 线性表顺序存储结构的创建、数据插入、数据获取、获取长度、删除数据、清空数据、销毁顺序存储结构方法的实现 ***/#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include "string.h"#define LIST_INIT_SIZE 100 // 线性表存储空间的初始分配量#define LISTINCREMENT 10 // 线性表存储空间的分配增量// 函数结果状态代码#define TRUE 1#define FALSE 0#define OK 1#define ERROR 0#define INFEASIBLE -1#define OVERLOW -2// Status 是函数的类型, 其值是函数结果状态代码typedef int Status;typedef int ElemType;// -----线性表的动态分配顺序存储结构-----typedef struct&#123; ElemType * elem; // 存储空间基址 int length; // 当前长度 int listsize; // 当前分配的存储容量(以sizeof(ElemType)为单位)&#125;SqList;// 操作结果：构造一个空的线性表LStatus InitList(SqList *L)&#123; // 为结构体中的存储空间分配内存 L-&gt;elem = (ElemType *)malloc(LIST_INIT_SIZE * sizeof(ElemType)); if(! L-&gt;elem) exit(OVERLOW); // 存储分配失败 L-&gt;length = 0; // 空表长度为0 L-&gt;listsize = LIST_INIT_SIZE; // 初始存储容量 return OK;&#125;// InitList_sq// 初始条件：线性表L已存在// 操作结果：销毁线性表LStatus DestroyList(SqList *L)&#123; // 判断指针是否为空 if (L == NULL) &#123; return ERROR; &#125; // 释放calloc, malloc, realloc动态分配的空间 free(L-&gt;elem); L-&gt;elem = NULL; L-&gt;length = 0; L-&gt;listsize = 0; return OK;&#125;// DestroyList// 初始条件：线性表L已存在// 操作结果：将L重置为空表。Status ClearList(SqList *L)&#123; // 判断指针是否为空 if (L == NULL) &#123; return ERROR; &#125; L-&gt;length = 0; return OK;&#125;// ClearList// 初始条件：线性表L已存在// 操作结果：若L为空表，则返回TRUE,否则返回FALSEStatus ListEmpty(SqList L)&#123; if (L.length == 0) return TRUE; else return FALSE;&#125;// ListEmpty// 初始条件：线性表L已存在// 操作结果：返回L中数据元素个数Status ListLength(SqList L)&#123; return L.length;&#125;// 初始条件：线性表L已存在, 1&lt;=i&lt;=ListLength(L)// 操作结果：用e返回L中第i个数据元素的值Status GetElem(SqList L, int i, ElemType *e)&#123; if (i&lt;1 || i&gt;L.length) exit(ERROR); *e =* (L.elem+i-1); return OK;&#125;// 初始条件：线性表L已存在，compare()是数据元素判定函数(满足为1,否则为0)。// 操作结果：返回L中第1个与e满足关系compare()的数据元素的位序。若这样的数据元素不存在，则返回值为0.Status LocateElem(SqList L, ElemType e, Status(*compare)(ElemType,ElemType))&#123; ElemType *p; int i = 1; // i的初值为第一个元素的位序 p = L.elem; // p的初值为第一个元素的存储位置 while (i &lt;= L.length &amp;&amp; !compare(*p++,e)) &#123; ++i; &#125; if (i&lt;=L.length) return i; else return ERROR;&#125;// 初始条件：线性表L已存在// 操作结果：若cur_e是L的数据元素，且不是第一个，则用pre_e返回它的前驱，否则操作失败，pre_e无定义Status PriorElem(SqList L, ElemType cur_e, ElemType *pre_e)&#123; int i = 2; ElemType *p = L.elem + 1; while (i &lt;= L.length &amp;&amp; *p!=cur_e) &#123; p++; i++; &#125; if (i&gt;L.length) return INFEASIBLE; else&#123; *pre_e = *--p; return OK; &#125;&#125;// 初始条件：线性表L已存在// 操作结果：若cur_e是L的数据元素，且不是最后一个，则用next_e返回它的后续，否则操作失败,next_e无定义Status NextElem(SqList L, ElemType cur_e, ElemType *next_e)&#123; int i = 1; ElemType *p = L.elem; while (i &lt; L.length &amp;&amp; *p!=cur_e) &#123; i ++; p ++; &#125; if (i == L.length) return INFEASIBLE; else&#123; *next_e = *++p; return OK; &#125;&#125;// 初始条件：线性表L已存在,1&lt;=i&lt;=ListLength(L)+1// 操作结果：在L中第i个位置之前插入新的数据元素e,L的长度加1Status ListInsert(SqList *L, int i, ElemType e)&#123; ElemType *newbase,*q,*p; if(i&lt;1 || i&gt;L-&gt;length+1) return ERROR; // i值不合法 if(L-&gt;length&gt;=L-&gt;listsize) // 当前存储空间已满,增加分配 &#123; newbase = (ElemType *)realloc(L-&gt;elem,(L-&gt;listsize + LISTINCREMENT) * sizeof(ElemType)); if(!newbase) exit(OVERLOW); // 存储分配失败 L-&gt;elem = newbase; // 新基址 L-&gt;listsize += LISTINCREMENT; // 增加存储容量 &#125; q=L-&gt;elem+i-1; /* q为插入位置 */ for(p=L-&gt;elem+L-&gt;length-1;p&gt;=q;--p) /* 插入位置及之后的元素右移 */ *(p+1)=*p; *q=e; /* 插入e */ ++L-&gt;length; /* 表长增1 */ return OK;&#125;// 初始条件：线性表L已存在且非空，1,=i&lt;=ListLength(L)// 操作结果：删除L的第i个数据元素，并用e返回其值,L的长度-1Status ListDelete(SqList *L, int i, ElemType *e)&#123; ElemType *p, *q; if (i&lt;1 || i&gt;L-&gt;length) return ERROR; // i值不合法 p = L-&gt;elem+i-1; // p为被删除元素的位置 *e = *p; // 被删除元素的值赋给e q = L-&gt;elem + L-&gt;length - 1; // 表尾元素的位置 for (++p; p&lt;=q; ++p) &#123; // 被删除元素之后的元素左移 *(p-1) = *p; L-&gt;length--; // 表长-1 &#125; return OK;&#125;// 初始条件：线性表L已存在// 操作结果：依次对L的每个数据元素调用函数vi()。一旦vi()失败，则操作失败Status ListTraverse(SqList L, void(*vi)(ElemType*))&#123; ElemType *p; int i; p = L.elem; for (i=1; i&lt;=L.length; i++) &#123; vi(p++); &#125; printf("\n"); return OK;&#125; 测试代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192//// main.c// arrlist//#include &lt;stdio.h&gt;#include "Arrlist.h"// 判断是否相等的函数，Union()用到Status equal(ElemType c1,ElemType c2)&#123; if(c1==c2) return TRUE; else return FALSE;&#125;// 将所有在线性表Lb中但不在La中的数据元素插入到La中void Union(SqList *La,SqList Lb)&#123; ElemType e; int La_len,Lb_len; int i; La_len=ListLength(*La); // 求线性表的长度 Lb_len=ListLength(Lb); for(i=1;i&lt;=Lb_len;i++) &#123; GetElem(Lb,i,&amp;e); // 取Lb中第i个数据元素赋给e if(!LocateElem(*La,e,equal)) // La中不存在和e相同的元素,则插入之 &#123; ListInsert(La,++La_len,e); &#125; &#125;&#125;void print(ElemType *c)&#123; printf("%d ",*c);&#125;int main(int argc, const char * argv[]) &#123; // insert code here... printf("Testing start!\n"); SqList La,Lb; ElemType t1,t2,t3; t1 = 10; t2 = 20; t3 = 30; int t1_length,t2_length,t3_length, i; // 构造一个空的线性表La InitList(&amp;La); // 插入数据元素t1 ListInsert(&amp;La, 1, t1); // 获取线性表长度 t1_length = ListLength(La); // 插入数据元素t2 ListInsert(&amp;La, 2, t2); t2_length = ListLength(La); // 插入数据元素t3 ListInsert(&amp;La, 3, t3); t3_length = ListLength(La); // 输出每次插入新元素后 表L的长度变化 printf("t1_length=%d,t2_length=%d,t3_length=%d\n",t1_length,t2_length,t3_length); // 输出表La的内容 printf("La= "); ListTraverse(La,print); // 在表Lb中插入5个元素 InitList(&amp;Lb); for (i=1; i&lt;=5; i++) &#123; ListInsert(&amp;Lb, i, 2 * i); &#125; // 输出表Lb的内容 printf("Lb= "); ListTraverse(Lb, print); // 输出表Lb长度 printf("Lb length = %d\n",ListLength(Lb)); // La U Lb Union(&amp;La, Lb); //输出新表L的内容 printf("new La= "); ListTraverse(La,print); printf("end!!!\n"); return 0;&#125; 运行结果，如下图所示： 时间复杂度插入算法的时间性能分析顺序表上的插入运算，时间主要消耗在了数据的移动上，在第i个位置上插入x ，从ai 到an 都要向下移动一个位置，共需要移动n－i＋1个元素，而i 的取值范围为：1&lt;= i&lt;= n+1，即有n＋1个位置可以插入。设在第i个位置上作插入的概率为Pi，则平均移动数据元素的次数： 因此，在顺序表上做插入操作需移动表中一半的数据元素。显然时间复杂度为Ｏ(n)。 删除算法的时间性能分析与插入运算相同，其时间主要消耗在了移动表中元素上，删除第i个元素时，其后面的元素ai+1～an 都要向上移动一个位置，共移动了n-i 个元素，所以平均移动数据元素的次数： 因此，顺序表上作删除运算时大约需要移动表中一半的元素，显然该算法的时间复杂度为Ｏ(n)。 结语 接下来，我将继续学习线性表的链式表示和实现 最近访客]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[数据结构之绪论]]></title>
      <url>%2F2017%2F04%2F25%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E7%BB%AA%E8%AE%BA%2F</url>
      <content type="text"><![CDATA[简介 什么是数据结构？一般来讲，用来解决一个具体问题时，大致需要下列几个步骤：首先从具体问题抽象出一个适当的数学模型，然后设计一个解此数学模型的算法，最后编出程序，进行测试，调整直至得到最终答案。 概念概括地说：数据结构是一门讨论“描述现实世界实体的数学模型（非数值计算）及其上的操作在计算机中如何表示和实现”的学科。或者说，数据结构是一门研究非数值计算的课程设计问题中计算机的操作对象以及它们之间的关系和操作等的学科。 示例 图书馆的数目检索系统采用线性关系的数据结构。 多叉路口交通灯的管理问题，采用了图状关系的数据结构。 计算机和人对弈的问题，采用了树形关系的数据结构。 基本概念和术语概念和术语1.数据： 所有能输入到计算机中，且能被计算机程序处理的符号的总称。是计算机操作的对象的总称。是计算机处理的信息的某种特定的符号表示形式。 2.数据元素： 是数据（集合）中的一个“个体”，是数据结构中讨论的基本单位。可由若干个数据项组成。 3.数据项： 数据结构中的最小单位。数据元素可以是数据项的集合。 例如：描述一个运动员的数据元素可以是：如下图 4.数据对象： 是性质相同的数据元素的集合，是数据的一个子集。 5.数据结构： 带结构的数据元素的集合。是相互之间存在一种或多种特定关系的数据元素的集合。 数据的逻辑结构的分类 集合：结构中的数据元素之间除了“同属一个集合”的关系外，别无其他关系。 线性结构：结构的数据元素之间存在着一对一的关系，即一个数据元素只与另一个数据元素有关系。 树形结构：结构的数据元素之间存在着一对多的关系，即一个数据元素只与另外多个数据元素有关系。 图状结构或网状结构：结构的数据元素之间存在着多对多的关系，即数据元素之间有多个关系。 如下图所示为上述4类基本结构的示意图： 数据结构的形式定义 数据结构是一个二元组：Data_Structures = (D,S)其中：D是数据元素的有限集，S是D上关系的有限集。 逻辑结构与物理结构 逻辑结构：数据元素之间的逻辑关系称为数据的逻辑结构。数据的逻辑结构可以看作是从具体问题抽象出来的数学模型，它与数据的存储无关。该结构是为了方便计算和理解，人为规定的。从数学的角度观察，逻辑结构可形式化定义为（D，R），D是数据元素的集合，R是D上关系的有限数据元素的集合。 物理结构：数据结构在计算机中的表示（又称映像）称为数据的物理结构，或称存储结构。它所研究的是数据结构在计算机中的实现方法，包括数据结构中元素的表示及元素间关系的表示。如线性结构，既要存储数据元素A，B，C，D又要存储他们之间的关系AB，BC，CD那么，是用一片连续的内存单元来存放这些记录（如用数组表示），还是随机存放各结点数据再用指针进行链接呢？这就是物理结构的问题。根据分析该结构是线性关系，故采用数组来存储。 顺序存储结构与链式存储结构 数据元素之间的关系在计算机中有两种不同的表示方法：顺序映像和非顺序映像，并由此得到两种不同的存储结构：顺序存储结构和链式存储结构。 顺序存储结构：以相对的存储位置表示后继关系。例如：令y的存储位置和x的存储位置之间差一个常量C，而C是一个隐含值，整个存储结构中只含数据元素本身的信息。如下图： 链式存储结构：以附加信息（指针）表示后继关系。需要用一个和x在一起的附加信息指示y的存储位置。如下图： 抽象数据类型 数据类型：是一个值的集合和定义在此集合上的一组操作的总称。在高级程序设计语言中，数据类型可分为两类：一类是非结构的原子类型，另一类则是结构类型。 抽象数据类型（Abstract Data Type，简称ADT）：是指一个数学模型以及定义在该模型上的一组操作。例如，抽象数据类型复数的定义： 123456ADT Complex&#123;数据对象： D = &#123;e1,e2|e1,e2∈RealSet&#125;数据关系： R1 = &#123;&lt;e1,e2&gt;|e1是复数的实数部分|e2是复数的虚数部分&#125;&#125; 抽象数据类型三元组的定义 123456789101112131415161718192021222324252627ADT Triplet &#123; 数据对象：D = &#123;e1,e2,e3|e1,e2,e3∈(定义了关系运算的某个集合)&#125; 数据关系：R1 = &#123;&lt;e1,e2&gt;,&lt;e2,e3&gt;&#125; 基本操作： InitTriplet(&amp;T, v1, v2, v3) 操作结果：构造了三元数组T，元素e1，e2和e3分别被赋以参数v1，v2和v3的值。 DestroyTriplet(&amp;T) 操作结果：三元组T被销毁。 Get(T, i, &amp;e) 初始条件：三元组T已存在，1&lt;=i&lt;=3。 操作结果：用e返回T的第i元的值。 Put(&amp;T, i, e) 初始条件：三元组T已存在，1&lt;=i&lt;=3。 操作结果：改变T的第i元的值为e。 IsAscending(T) 初始条件：三元组T已存在。 操作结果：如果T的3个元素按升序排列，则返回1，否则返回0。 Isdescenting(T) 初始条件：三元组T已存在。 操作结果：如果T的3个元素按降序排列，则返回1，否则返回0。 Max(T,&amp;e) 初始条件：三元组T已存在。 操作结果：用e返回T的3个元素中的最大值。 Min(T,&amp;e) 初始条件：三元组T已存在。 操作结果：用e返回T的3个元素中的最小值。&#125;ADT Triplet 抽象数据类型三元组的实现 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647Status InitTriplet(Triplet &amp;T,ElemType v1,ElemType v2,ElemType v3)&#123; //构造三元组T，依次置T的3个元素的初值为v1，v2，v3. T = (ElemType * ) malloc (3 * sizeof(ElemType)); //分配3个元素的存储空间 if(!T) exit(OVERFLOW); //分配存储空间失败 T[0] = v1; T[1] = v2; T[2] = v3; return OK;&#125; // InitTripletStatus DestroyTriplet(Triplet &amp;T)&#123; // 销毁三元组 free(T); T = NULL; return OK;&#125; // DestroyTripletStatus Get(Triplet T,int i,ElemType %e)&#123; // 1 &lt;= 3,用e返回T第i元的值。 if(i&lt;1 || i&gt;3) return ERROR; e = T[i-1]; return OK;&#125; // GetStatus Put(Triplet &amp;T,int i,ElemType e)&#123; // 1 &lt;= 3,用e返回T第i元的值。 if(i&lt;1 || i&gt;3) return ERROR; T[i-1] = e; return OK; &#125; // putStatus IsAscending(Triplet T)&#123; // 如果T的3个元素按照升序排列，则返回1，否则返回0 return (T[0]&gt;=T[1])&amp;&amp;(T[1]&gt;=T[2]);&#125; // IsAscendingStatus IsDesending(Triplet T)&#123; // 如果T的3个元素按照升序排列，则返回1，否则返回0 return (T[0]&lt;=T[1])&amp;&amp;(T[1]&lt;=T[2]);&#125; // IsDesendingStatus Max(Triplet T,ElemType &amp;e)&#123; e = (T[0] &gt;= T[1]) ? (T[0] &gt;= T[2] ? T[0] : T[2]) : (T[1] &gt;= T[2] ? T[1] : T[2]); return OK;&#125; //MaxStatus Min(Triplet T,ElemType &amp;e)&#123; e = (T[0] &lt;= T[1]) ? (T[0] &lt;= T[2] ? T[0] : T[2]) : (T[1] &lt;= T[2] ? T[1] : T[2]); return OK;&#125; //Min 数据结构之抽象数据类型三元组的完整实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101//宏定义#define TRUE 1#define OK 1#define ERROR 0#define FASE 0#define INFEASIBLE -1#define OVERFLOW -2//头文件#include&lt;stdlib.h&gt;#include&lt;stdio.h&gt;typedef int Status;typedef int *Triplet;//初始化三元组int initTriplet(Triplet &amp;T, int v1, int v2, int v3)&#123; T = (int *)malloc(3 * sizeof(int)); if (!T) &#123; exit(OVERFLOW); &#125; T[0] = v1; T[1] = v2; T[2] = v3; return OK;&#125;//销毁三元组int destroyTriplet(Triplet &amp;T)&#123; free(T); T= NULL; return OK;&#125;//获取三元组中的值int get(Triplet T, int i, int &amp;e)&#123; if (i &lt; 1 || i&gt;3)return ERROR; e = T[i - 1]; return OK;&#125;//向三元组中插入值int put(Triplet T, int i, int e)&#123; if (i &lt; 1 || i&gt;3)return ERROR; T[i - 1] = e; return OK;&#125;//判断是否升序int isAscending(Triplet T)&#123; return T[0] &lt;= T[1] &amp;&amp; T[1] &lt;= T[2]; return OK;&#125;//判断是否降序int isDscending(Triplet T)&#123; return T[0] &gt;= T[1] &amp;&amp; T[1] &gt;= T[2]; return OK;&#125;//求三元组中的最大值int max(Triplet T, int &amp;e)&#123; e = T[0] &gt;= T[1] ? (T[0] &gt;= T[2] ? T[0] : T[2]) : (T[1] &gt;= T[2] ? T[1] : T[2]); return OK;&#125;//求三元组中的最小值int min(Triplet T, int &amp;e)&#123; e = T[0] &lt;= T[1] ? (T[0] &lt;= T[2] ? T[0] : T[2]) : (T[1] &lt;= T[2] ? T[1] : T[2]); return OK;&#125;//测试int main()&#123; int *t = NULL; int e; initTriplet(t,1,2,3); get(t, 1, e); printf("%d %d %d\n", e,t[1],t[2]); put(t, 1, 4); printf("%d %d %d\n", t[0], t[1], t[2]); initTriplet(t, 1, 2, 3); if (isAscending(t))printf("YES\n"); initTriplet(t, 3, 2, 1); if (isDscending(t))printf("YES\n"); max(t, e); printf("%d\n",e); min(t, e); printf("%d\n", e);&#125; 算法和算法分析算法的特性 算法（Algorithm）是对特定问题求解步骤的一种描述，是指令的有限序列。其中每一条指令表示一个或多个操作。一个算法应该具有下列特性：⑴ 有穷性。一个算法必须在有穷步之后结束，即必须在有限时间内完成。⑵ 确定性。算法的每一步必须有确切的定义，无二义性。算法的执行对应着的相同的输入仅有唯一的一条路经。⑶ 可行性。算法中的每一步都可以通过已经实现的基本运算的有限次执行得以实现。⑷ 输入。一个算法具有零个或多个输入，这些输入取自特定的数据对象集合。⑸ 输出。一个算法具有一个或多个输出，这些输出同输入之间存在某种特定的关系。 算法设计要求：⑴ 正确性。算法的执行结果应当满足预先规定的功能和性能要求。⑵ 可读性。一个算法应当思路清晰、层次分明、简单明了、易读易懂。⑶ 健壮性。当输入不合法数据时，应能作适当处理，不至引起严重后果。⑷ 效率与低存储量要求（高效）。有效使用存储空间和有较高的时间效率。 算法性能分析与度量 算法效率的度量：度量一个程序的执行时间通常有两种方法：（1）事后统计的方法 缺点：a.必须执行程序 b.其他因素掩盖算法本质（2）事后分析估计的方法 一个高级语言编写的程序在计算机上运行所消耗的时间取决于下列因素：a.算法选用的策略 b.问题的规模 c.编写程序的语言 d.编译程序产生的机器代码的质量 e.计算机执行指令的速度 时间复杂度一个程序的时间复杂度（Time complexity）是指程序运行从开始到结束所需要的时间。 一个算法是由控制结构和原操作构成的，其执行时间取决于两者的综合效果。为了便于比较同一问题的不同的算法，通常的做法是：从算法中选取一种对于所研究的问题来说基本运算的原操作，以该原操作重复执行的次数作为算法的时间度量。 一般情况下，算法中基本操作重复执行的次数是规模n 的某个函数f(n),算法的时间度量记作T(n) = O(f(n))它表示随着问题规模n的增大，算法执行时间的增长率和f(n)的增长率相同，称作算法的渐进时间复杂度，简称时间复杂度（Time complexity） 例如，一个程序的实际执行时间为T(n)＝2.7n3+3.8n2+5.3。则T(n)＝Ο(n3)。使用大Ο记号表示的算法的时间复杂度，称为算法的渐进时间复杂度(Asymptotic Time Complexity)。 通常用Ο(1)表示常数计算时间。常见的渐进时间复杂度有：Ο(1)＜Ο(log2n)＜Ο(n)＜Ο(nlog2n)＜Ο(n2)＜Ο(n3)＜Ο(2n) 空间复杂度一个程序的空间复杂度（Space complexity）是指程序运行从开始到结束所需的存储量。 算法的空间复杂度的定义为：S(n) = O(g(n))表示随着问题规模n的增大，算法运行所需存储量的增长率相同。 算法的存储量包括：a.输入数据所占空间 b.程序本身所占空间 c.辅助变量所占空间 结语 接下来，我将继续学习数据结构！！！ 最近访客]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring Boot快速入门]]></title>
      <url>%2F2017%2F04%2F18%2FSpring-Boot%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%2F</url>
      <content type="text"><![CDATA[简介 介绍Spring 框架是非常著名的 Java 开源框架，历经十多年的发展，整个生态系统已经非常完善甚至是繁杂，Spring Boot 正是为了解决这个问题而开发的，为 Spring 平台和第三方库提供了开箱即用的设置，只需要很少的配置就可以开始一个 Spring 项目。当然，建议使用 Java 8 来进行开发。 特征 创建独立的Spring应用程序 为所有Spring开发者更快的入门 开箱即用，但通过不采用默认设置可以快速摆脱这种方式。 提供一系列大型项目常用的非功能性特征，比如：内嵌服务器，安全，指标，健康检测，外部化配置 没有冗余代码生成和XML配置的要求 系统要求 JDK1.7以上 Spring Boot1.5.2以上 快速入门 本篇的主要目标是完成Spring Boot 基础项目的构建，并且实现一个简单的Http请求处理，通过这个例子（Hello World）对Spring Boot 有一个初步的了解，并体验其结构的简单，方便和快速，实现基本的Spring Boot 的快速入门 新建工程1.首先打开IDEA（当然，没有IDEA的，可以前往这里IDEA下载下载一个），新建一个项目，如下图所示: 2.选择 Spring Initializr，这里的SDK为JAVA下载的JDK，如图所示： 3.上面执行之后，一路next，就可以了，当然，要是想修改一下工程的名字，可以在如下图所示的位置修改： 4.如下图所示，是工程新建后的目录： 编写代码1.打开上面目录下的pom.xml文件，在里面添加如下依赖： 1234567891011&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.2.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2.打开上面的目录下的DemoApplication，编写“Hello World”简单程序，参考代码如下： 123456789101112131415161718192021package com.example;import org.springframework.boot.*;import org.springframework.boot.autoconfigure.*;import org.springframework.stereotype.*;import org.springframework.web.bind.annotation.*;@Controller@EnableAutoConfigurationpublic class SampleController &#123; @RequestMapping("/") @ResponseBody String home() &#123; return "Hello World!"; &#125; public static void main(String[] args) throws Exception &#123; SpringApplication.run(SampleController.class, args); &#125;&#125; 运行工程在上面的目录下的DemoApplication上，点击鼠标右键，有个运行工程（run ‘DemoApplication’）,点击即可运行，如下图所示： 也可以在DemoApplication中点击右键运行，和上面大概一样。 查看效果1.Spring Boot 工程中，默认的端口号为：8080，打开浏览器，在网址上输入：localhost:8080，即可观看到如下效果： 2.还可以修改Spring Boot 工程中的端口号，在上面的目录中打开resources文件下的application.properties，在里面输入： 1server.port=8000 然后，再重复上面的“运行工程”和“查看效果”的步骤，可以发现和上面的效果是一样的。 结语 至此已完成目标，通过一个小的例子（Hello World）,实现了Spring Boot整个简单过程的快速入门。知道了如何Spring Boot 的作用，方便以后的学习。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[如何在github上展示前端页面]]></title>
      <url>%2F2017%2F04%2F16%2F%E5%A6%82%E4%BD%95%E5%9C%A8github%E4%B8%8A%E5%B1%95%E7%A4%BA%E5%89%8D%E7%AB%AF%E9%A1%B5%E9%9D%A2%2F</url>
      <content type="text"><![CDATA[前言 如何将自己做的前端页面放在网上供他人浏览，是不是必须要有一台服务器和域名呢？我的答案是“不是必须的，一个github就可以搞定了！”github是一个很好的代码管理与协同开发平台，要是你没有github账号，你就缺失了学习资源的一大财富！下面我将介绍如何在github上部署前端页面！ 步骤 安装git1.Mac用户：mac自带git命令功能，无需安装。2.Windows用户：你可以前往windows地址下载并安装。 创建仓库当然，在你创建一个仓库的前提是：首先你有一个自己的github账号。1.在你的github主页，我们可以点击右上角（头像左边）的加号按钮下的“New repository”来新建一个项目仓库，如图所示： 2.开始创建一个仓库demo，如图所示： 运用git上传代码仓库建立完毕后，这时候就需要用我们之前安装的git命令来将本地的代码推送到github上了。如果你仅为了展示自己的前端页面，那么只要掌握如下命令即可。1.打开你的目录 1$ cd demo 2.初始化版本库，用于生成.git文件 1$ git init 3.将所有文件添加到缓存区 1$ git add * 4.提交当前工作空间的修改内容 1$ git commit -m "first commit" 5.将仓库连接到远程服务器 1$ git remote add origin &lt;server&gt; 这里的server地址为是建的仓库的server地址，如下图所示： 6.将改动推送到所添加的服务器上 1$ git push -u origin master 创建分支上面的步骤只是将自己的代码提交到github上，但要是想要将自己的页面展示给别人，则需要创建一个分支，基本操作步骤如下：1.如图所示：”输入demo1时，点击“Create branch:demo1 from’master’”，即可创建。 2.新建分支demo1后，在github上切换到demo1分支上，再进行如下操作： 1$ git checkout --orphan demo1 123$ git add *$ git commit -m "update"$ git push -u origin gh-pages 这样，我们的demo项目就多了一个demo1分支，里面的代码文件主要的作用就是用来展示前端页面的。 在浏览器访问页面上面的都操作完后，我们就可以来访问自己的页面了。1.访问页面的网址格式如下： 1$ https://&lt;github用户名&gt;.github.io/demo/ 2.我的例子的网址为：https://tonynyl.github.io/yuanlong/，展示效果如下：]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Hello World]]></title>
      <url>%2F2017%2F03%2F31%2FHello%20World%2F</url>
      <content type="text"><![CDATA[blah blah blah Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment 最近访客]]></content>
    </entry>

    
  
  
</search>
